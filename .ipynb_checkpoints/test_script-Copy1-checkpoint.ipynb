{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGreedy_optimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from Environment import Environment\n",
    "from UserCat import UserCat\n",
    "from Product import Product\n",
    "from Greedy_optimizer import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING of ENVIRONMENT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=[]\n",
    "products=[]\n",
    "\n",
    "nameofproduct= [ #name of products\n",
    "    \"Calabazas\",\n",
    "    \"Hinojo\",\n",
    "    \"Sesamo\",\n",
    "    \"Girasol\",\n",
    "    \"Amapola\"\n",
    "]\n",
    "\n",
    "prices=[[4., 6, 7, 8],\n",
    "    [9., 13, 17, 21],\n",
    "    [18., 20, 22, 24],\n",
    "    [24., 26, 28, 30],\n",
    "    [33., 35, 37, 39]]\n",
    "#1-2 di delta, Con sovrapposizione\n",
    "\n",
    "cost=[2,4.5,9,14,17]\n",
    "\n",
    "#sarebbe interessante anche prendere da file il tutto così da cambiare tutto più facilmente\n",
    "#calcolo i margini dai cost mi sembra più sensato e anche più veloce se dobbiamo cambiare continuamente\n",
    "\n",
    "cost2 = np.tile(np.array([cost]).transpose(), (1, 4))\n",
    "margins = np.array(prices)-cost2\n",
    "\n",
    "Secondary_dict={           # Propongo i prodotti più simili a quello mostrato --> problemino: 2 viene mostrato quasi sempre\n",
    "    \"Calabazas\": [1,2],\n",
    "    \"Hinojo\": [0,2],\n",
    "    \"Sesamo\": [1,3],\n",
    "    \"Girasol\": [2,4],\n",
    "    \"Amapola\": [2,3]\n",
    "}\n",
    "\n",
    "res_price_params = {\n",
    "    \"shape\": 150,  # media è shape*scale, la varianza è shape*scale^2\n",
    "    \"scale\": 0.2,\n",
    "    \"max\" : 60,\n",
    "    \"min\" : 5\n",
    "}\n",
    "\n",
    "np.random.seed(1)\n",
    "probabilities = [[0, 0.3, 0.2, 0, 0],\n",
    "                 [0.3, 0, 0.3, 0, 0],\n",
    "                 [0, 0.2, 0, 0.4, 0],\n",
    "                 [0, 0, 0.2, 0, 0.4],\n",
    "                 [0, 0, 0.3, 0.3, 0]]\n",
    "probabilities = np.matrix(probabilities)\n",
    "\n",
    "\n",
    "alphas=[1/5, 1/5, 1/5, 1/5, 1/5] \n",
    "# per ora li generiamo così, tutti uguali -> devo generare 3 diversi vettori alpha\n",
    "\n",
    "poisson_lambda = 0.7\n",
    "#=valore atteso del numero di prodotti acquistati (specifico per prodotto)...non dipende dal\n",
    "#prodotto oltre che dallo user che dal tipo di user che\n",
    "\n",
    "# p_users = [4/9, 3/9, 2/9] #probabilità di essere un tipo di utente-> da cambiare\n",
    "p_users = [1]\n",
    "\n",
    "lambda_q = 0.5 #just my idea of lambda\n",
    "#possiamo stimarlo con i dati passati provenienti dal sito -> vino tot è stato comprato 15 volte\n",
    "\n",
    "#proviamo a pensare, ha senso vederlo come coppia? categoria-prodotto? Avrei 3 categorie *5 prodotti-> 15 lambda diversi\n",
    "# ^^ Andre: secondo me ha senso avere 3 lambda_q diversi per categoria MA non per prodotto. La probabilità di continuare\n",
    "#           a guardare secondo me dipende dall'utente e non dal prodotto\n",
    "\n",
    "for i in range (5):\n",
    "    products.append(Product(prices[i], i, nameofproduct[i],margins[i]))\n",
    "\n",
    "# for i in range(3):\n",
    "users.append(UserCat(alphas, res_price_params, poisson_lambda, probabilities))\n",
    "\n",
    "Env = Environment(users, products,  lambda_q, Secondary_dict, p_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Reward test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "users=[]\n",
    "products=[]\n",
    "\n",
    "nameofproduct= [ #name of products\n",
    "    \"Calabazas\",\n",
    "    \"Hinojo\",\n",
    "    \"Sesamo\",\n",
    "    \"Girasol\"\n",
    "]\n",
    "\n",
    "prices=[[4., 6, 7, 8],\n",
    "    [9., 13, 17, 21],\n",
    "    [18., 20, 22, 24],\n",
    "    [24., 26, 28, 30]]\n",
    "#1-2 di delta, Con sovrapposizione\n",
    "\n",
    "cost=[2,4.5,9,14]\n",
    "\n",
    "#sarebbe interessante anche prendere da file il tutto così da cambiare tutto più facilmente\n",
    "#calcolo i margini dai cost mi sembra più sensato e anche più veloce se dobbiamo cambiare continuamente\n",
    "\n",
    "cost2 = np.tile(np.array([cost]).transpose(), (1, 4))\n",
    "margins = np.array(prices)-cost2\n",
    "\n",
    "Secondary_dict={           # Propongo i prodotti più simili a quello mostrato --> problemino: 2 viene mostrato quasi sempre\n",
    "    \"Calabazas\": [1,2],\n",
    "    \"Hinojo\": [0,2],\n",
    "    \"Sesamo\": [1,3],\n",
    "    \"Girasol\": [1,2]\n",
    "}\n",
    "\n",
    "res_price_params = {\n",
    "    \"shape\": 150,  # media è shape*scale, la varianza è shape*scale^2\n",
    "    \"scale\": 0.2,\n",
    "    \"max\" : 60,\n",
    "    \"min\" : 5\n",
    "}\n",
    "\n",
    "np.random.seed(1)\n",
    "probabilities = [[0, 0.3, 0.2, 0],\n",
    "                 [0.3, 0, 0.3, 0],\n",
    "                 [0, 0.2, 0, 0.4],\n",
    "                 [0, 0.2, 0.3, 0]]\n",
    "probabilities = np.matrix(probabilities)\n",
    "\n",
    "\n",
    "alphas=[1/5, 1/5, 1/5, 1/5, 1/5] \n",
    "# per ora li generiamo così, tutti uguali -> devo generare 3 diversi vettori alpha\n",
    "\n",
    "poisson_lambda = 0.7\n",
    "#=valore atteso del numero di prodotti acquistati (specifico per prodotto)...non dipende dal\n",
    "#prodotto oltre che dallo user che dal tipo di user che\n",
    "\n",
    "# p_users = [4/9, 3/9, 2/9] #probabilità di essere un tipo di utente-> da cambiare\n",
    "p_users = [1]\n",
    "\n",
    "lambda_q = 0.5 #just my idea of lambda\n",
    "#possiamo stimarlo con i dati passati provenienti dal sito -> vino tot è stato comprato 15 volte\n",
    "\n",
    "#proviamo a pensare, ha senso vederlo come coppia? categoria-prodotto? Avrei 3 categorie *5 prodotti-> 15 lambda diversi\n",
    "# ^^ Andre: secondo me ha senso avere 3 lambda_q diversi per categoria MA non per prodotto. La probabilità di continuare\n",
    "#           a guardare secondo me dipende dall'utente e non dal prodotto\n",
    "\n",
    "for i in range (4):\n",
    "    products.append(Product(prices[i], i, nameofproduct[i],margins[i]))\n",
    "\n",
    "# for i in range(3):\n",
    "users.append(UserCat(alphas, res_price_params, poisson_lambda, probabilities))\n",
    "\n",
    "Env_prova = Environment(users, products,  lambda_q, Secondary_dict, p_users)\n",
    "\n",
    "# CASI POSSIBILI\n",
    "# Guardare documento word su trello nella scheda TEST EXPECTED REWARD\n",
    "# 0 a): b0*(1-q01)*(1-q02)*m0 \n",
    "# 0 b) : b0*q01*(1-b1)*[(1-q02)+q02*(1-b2)]*m0\n",
    "# 0-1 a) :b0*q01*b1*q12*(1-b2)*[m0+m1]\n",
    "# 0-1 b): b0*q01*b1*(1-q12)*[(1-q02)+q02*(1-b2)]*[m0+m1]\n",
    "# 0-2 a): b0*(1-q01)*q02*b2*{(1-q21)*(1-q23)+ q21*(1-b1)*[(1-q23) + q23*(1-b3)]}*[m0+m2]\n",
    "# 0-2 b) : b0*q01*(1-b1)*q02*b2*[q23*(1-b3)+(1-q23)]* [m0+m2]\n",
    "# 0-1-2 a): b0*q01*b1*q12*b2*[q23*(1-b3)*(1-q23)] *[m0+m1+m2]\n",
    "# 0-1-2 b): b0*q01*b1*(1-q12)*(q02)*b2*[q23*(1-b3)*(1-q23)] *[m0+m1+m2]\n",
    "# 0-1-2-3 a) : b0*q01*b1*q12*b2*q23*b3*[m0+m1+m2+m3]\n",
    "# 0-1-2-3 b) : b0*q01*b1*(1-q12)*q02*b2*q23*b3*[m0+m1+m2+m3]\n",
    "# 0-2-3 a) : b0*q01*(1-b1)*q02*b2*q23*b3*[m0+m2+m3]\n",
    "# 0-2-3 b) : b0*(1-q01)*q02*b2*q21*(1-b1)*q23*b3*[m0+m2+m3]\n",
    "# 0-2-3 c) : b0*(1-q01)*q02*b2*(1-q21)*q23*b3*[q31*(1-b1)+(1-q31)] *[m0+m2+m3]\n",
    "# 0-2-3-1 : b0*(1-q01) *q02*b2*q23*b3*q31*b1[m0+m1+m2+m3]\n",
    "# 0-2-1 : b0*(1-q01)*q02*b2*q12*b1*[q23*(1-b23)+(1-q23)]*[m0+m1+m2]\n",
    "\n",
    "# definisco i valori teorici\n",
    "b0 = Env_prova.theoretical_values[\"conversion_rates\"][0][0][0]\n",
    "b1 = Env_prova.theoretical_values[\"conversion_rates\"][0][1][0]\n",
    "b2 = Env_prova.theoretical_values[\"conversion_rates\"][0][2][0]\n",
    "b3 = Env_prova.theoretical_values[\"conversion_rates\"][0][3][0]\n",
    "\n",
    "q01 = Env_prova.theoretical_values[\"graph_weights\"][0][0,1]\n",
    "q02 = lambda_q * Env_prova.theoretical_values[\"graph_weights\"][0][0,2]\n",
    "q10 = Env_prova.theoretical_values[\"graph_weights\"][0][1,0]\n",
    "q12 = lambda_q * Env_prova.theoretical_values[\"graph_weights\"][0][1,2]\n",
    "q21 = Env_prova.theoretical_values[\"graph_weights\"][0][2,1]\n",
    "q23 = lambda_q * Env_prova.theoretical_values[\"graph_weights\"][0][2,3]\n",
    "q31 = Env_prova.theoretical_values[\"graph_weights\"][0][3,1]\n",
    "q32 = lambda_q * Env_prova.theoretical_values[\"graph_weights\"][0][3,2]\n",
    "\n",
    "m0 = margins[0,0] * Env_prova.theoretical_values[\"n_prod_sold\"][0]\n",
    "m1 = margins[1,0] * Env_prova.theoretical_values[\"n_prod_sold\"][0]\n",
    "m2 = margins[2,0] * Env_prova.theoretical_values[\"n_prod_sold\"][0]\n",
    "m3 = margins[3,0] * Env_prova.theoretical_values[\"n_prod_sold\"][0]\n",
    "\n",
    "theoretical_reward = ( b0*(1-q01)*(1-q02)*m0 + b0*q01*(1-b1)*((1-q02)+q02*(1-b2))*m0 + b0*q01*b1*q12*(1-b2)*(m0+m1) +\n",
    "b0*q01*b1*(1-q12)*((1-q02)+q02*(1-b2))*(m0+m1) + b0*(1-q01)*q02*b2*((1-q21)*(1-q23)+ q21*(1-b1)*((1-q23) + q23*(1-b3)))*(m0+m2) +\n",
    "b0*q01*(1-b1)*q02*b2*(q23*(1-b3)+(1-q23))* (m0+m2) + b0*q01*b1*q12*b2*(q23*(1-b3)*(1-q23)) *(m0+m1+m2) + \n",
    "b0*q01*b1*(1-q12)*(q02)*b2*(q23*(1-b3)*(1-q23)) *(m0+m1+m2) + b0*q01*b1*q12*b2*q23*b3*(m0+m1+m2+m3) +\n",
    "b0*q01*b1*(1-q12)*q02*b2*q23*b3*(m0+m1+m2+m3) + b0*(1-q01)*q02*b2*q21*(1-b1)*q23*b3*(m0+m2+m3) +\n",
    "b0*(1-q01)*q02*b2*(1-q21)*q23*b3*(q31*(1-b1)+(1-q31))*(m0+m2+m3) + b0*(1-q01) *q02*b2*q23*b3*q31*b1*(m0+m1+m2+m3)+\n",
    "b0*(1-q01)*q02*b2*q12*b1*(q23*(1-b3)+(1-q23))*(m0+m1+m2) )\n",
    "\n",
    "product = products[0]\n",
    "price_combination = [0, 0, 0, 0]\n",
    "user_index = 0\n",
    "\n",
    "Env_prova.expected_reward(price_combination)\n",
    "\n",
    "algo_reward = Env_prova.product_reward(product, [], [0], [Product([], -1, \"null\", [])], price_combination, user_index)\n",
    "print(\"theoretical reward :\", theoretical_reward)\n",
    "print(\"environment reward :\", algo_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env_prova.theoretical_values[\"conversion_rates\"][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env.optimal_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env.expected_reward(price_combination = [3, 3, 3, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env.theoretical_values[\"conversion_rates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Env.simulate_day(10000, [1,1,1,0,1], [\"conversion_rates\"])\n",
    "a['CR_vector']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_optimizer = Greedy_optimizer(Env)\n",
    "greedy_optimizer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 : Uncertain Convertion Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from step3_learner import TS_learner3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a = np.ones((5,4))\n",
    "b = np.ones((5,4))\n",
    "initial_beta = [a, b]\n",
    "learner = TS_learner3(initial_beta, Env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 100\n",
    "daily_users = 200\n",
    "n_days = 300\n",
    "\n",
    "for i in range(n_runs) :\n",
    "    learner.run(n_days, daily_users)\n",
    "\n",
    "opt_reward = learner.opt_reward\n",
    "collected_rewards = learner.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Salvo la history su file in modo che siamo sicuri ti riuscire a recuperarla anche in un secondo momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_rewards', 'wb') as f: \n",
    "    pickle.dump(collected_rewards, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Per recuperare, invece, i risultati ottenuti in un secondo momento :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_rewards', 'rb') as f: \n",
    "    collected_rewards = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward - collected_rewards, axis=0)), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "#plt.plot(np.cumsum(np.mean(opt - gr_rewards_per_experiment, axis=0)), 'g') #'g' stay for green, the color for the Greedy algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(np.std(opt_reward - collected_rewards, axis=0), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "#plt.plot(np.std(opt - gr_rewards_per_experiment, axis=0), 'g')  #'g' stay for green, the color for the Greedy algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are now computing the (theoretical) expected reward from each arm in the history (for each \"experiment\")\n",
    "#### In any case I think it is more correct collecting and store the reward collected for any iteration of the algorithm inside a class attribute of the learner (as in the exercitation code). In this way we can also deal easier with more complex cases where the uncertain value are also the alpha ratios, n_prod and graph weights different from none, and simply manage also the case of abrupt changes, or cases of code/logic/numeric changes in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env.theoretical_values[\"conversion_rates\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env.simulate_day(200, [1,1,1,1,0], [\"conversion_rates\", \"alpha_ratios\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(opt_reward - collected_rewards)[1][-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
