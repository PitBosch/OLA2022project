{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from regret_bound import *\n",
    "from Environment import *\n",
    "from UserCat import UserCat\n",
    "from Product import Product\n",
    "from Greedy_optimizer import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from step3_ucb1 import *\n",
    "from step4_ucb1 import *\n",
    "from step5_ucb1 import *\n",
    "from step6_sw_ucb import *\n",
    "from Step6_CD import *\n",
    "from step7_ucb1 import *\n",
    "from Step3_TS import *\n",
    "from Step4_TS import *\n",
    "from Step5_TS import *\n",
    "from Step6_TS_sw import *\n",
    "from Step7_TS import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT DEFINITION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Environment fixed informations and Products definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "products=[]\n",
    "\n",
    "nameofproduct= [ #name of products\n",
    "    \"Calabazas\",\n",
    "    \"Hinojo\",\n",
    "    \"Sesamo\",\n",
    "    \"Girasol\",\n",
    "    \"Amapola\"\n",
    "]\n",
    "# Dictionary fixing the secondary products linked to\n",
    "secondary_dict= {\n",
    "    \"Calabazas\": [1,2],\n",
    "    \"Hinojo\": [0,2],\n",
    "    \"Sesamo\": [3,1],\n",
    "    \"Girasol\": [2,4],\n",
    "    \"Amapola\": [3,2]\n",
    "}\n",
    "\n",
    "# Matrix n_prod*n_prices collecting the possible prices for each product. Prices are in ascending order\n",
    "prices = [[6.5, 8, 9.5, 11],\n",
    "          [11., 12, 13, 16],\n",
    "          [20., 21, 22, 25],\n",
    "          [27., 29, 31, 37],\n",
    "          [40., 41, 44, 48]]\n",
    "# Production cost of the products\n",
    "cost = [4.75, 9.75, 13.5, 15.75, 15.75]\n",
    "\n",
    "#sarebbe interessante anche prendere da file il tutto così da cambiare tutto più facilmente\n",
    "#calcolo i margini dai cost mi sembra più sensato e anche più veloce se dobbiamo cambiare continuamente\n",
    "# Computation of margins linked to each product for a particular choice of price\n",
    "cost2 = np.tile(np.array([cost]).transpose(), (1, 4))\n",
    "margins = np.array(prices)-cost2\n",
    "# Creation of the 5 objects of Product class\n",
    "for i in range (5):\n",
    "    products.append(Product(prices[i], i, nameofproduct[i],margins[i]))\n",
    "\n",
    "# Parameter for the computation of the click probability on the SECOND secondary product\n",
    "lambda_q = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 1: Young and Inexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_1 = {\n",
    "    \"mean\": [8.5, 13, 21.5, 28, 40],\n",
    "    \"std\": [1, 1.5, 2, 2.5, 3]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_1 = [[0, 0.6, 0, 0, 0],\n",
    "                   [0.4, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0.2, 0],\n",
    "                   [0, 0, 0.3, 0, 0.1],\n",
    "                   [0, 0, 0.2, 0.4, 0]]\n",
    "prob_lambda_1 = lambda_correct(np.matrix(probabilities_1), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_1 = [15, 15, 10, 5, 5]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_1 = [2, 1, .5, .2, .1]\n",
    "\n",
    "user1 = UserCat(alphas_1, res_price_params_1, poisson_lambda_1, prob_lambda_1, 'Young and Not Expert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 2: Old and Inexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_2 = {\n",
    "    \"mean\": [9, 14, 25, 32, 44],\n",
    "    \"std\": [3, 1.5, 2.5, 3.5, 4]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_2 = [[0, 0.4, 0, 0, 0],\n",
    "                 [0.3, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0.4, 0],\n",
    "                 [0, 0, 0.4, 0, 0.2],\n",
    "                 [0, 0, 0.4, 0.2, 0]]\n",
    "prob_lambda_2 = lambda_correct(np.matrix(probabilities_2), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_2 = [7, 12, 12, 12, 7]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_2 = [0.6, 1.1, 2, 0.9, 0.5]\n",
    "\n",
    "user2 = UserCat(alphas_2, res_price_params_2, poisson_lambda_2, prob_lambda_2, 'Old and Not Expert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 3: Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_3 = {\n",
    "    \"mean\": [7.5, 12, 23, 37, 49],\n",
    "    \"std\": [1.5, 1.5, 2, 4, 3.5]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_3 = [[0, 0.3, 0, 0, 0],\n",
    "                 [0.3, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0.5, 0],\n",
    "                 [0, 0, 0.2, 0, 0.6],\n",
    "                 [0, 0, 0.3, 0.5, 0]]\n",
    "prob_lambda_3 = lambda_correct(np.matrix(probabilities_3), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_3 = [5, 5, 10, 15, 15]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_3 = [0.1, 0.2, 0.5, 1.5, 1.2]\n",
    "\n",
    "user3 = UserCat(alphas_3, res_price_params_3, poisson_lambda_3, prob_lambda_3, 'Expert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 0: Aggregated demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_0 = {\n",
    "    \"mean\": [9, 13, 22, 35, 42],\n",
    "    \"std\": [3, 1.5, 2, 2.5, 2.5]\n",
    "}\n",
    "\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_0 = [[0, 0.5, 0, 0, 0],\n",
    "                 [0.4, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0.4, 0],\n",
    "                 [0, 0, 0.5, 0, 0.4],\n",
    "                 [0, 0, 0.2, 0.4, 0]]\n",
    "prob_lambda_0 = lambda_correct(np.matrix(probabilities_0), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_0 = [10, 10, 10, 10, 10]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_0 = [1.5, 1, .5, .4, .2]\n",
    "\n",
    "user0 = UserCat(alphas_0, res_price_params_0, poisson_lambda_0, prob_lambda_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Environment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON\n",
    "# probability distribution of the features\n",
    "# the following list has to be interpreted in the following way:\n",
    "# values_i is the parameter of the bernoulli for feature i; in our case feature0 is 1(0) for Expert(Not Expert)\n",
    "# while feature1 is 1(0) for Old(Young)\n",
    "feature_prob = [0.3, 0.4]\n",
    "# CASE WITH 3 USERS :\n",
    "# list of users \n",
    "users3 = [user1, user2, user3]\n",
    "feature_matrix3 = np.array([[0, 1], [2, 2]]) # values represent the label of the User Category\n",
    "env3 = Environment(users3, products, secondary_dict, feature_matrix3, feature_prob)\n",
    "\n",
    "# CASE WITH AGGREGATED USER :\n",
    "users0 = [user0]\n",
    "feature_matrix0 = np.array([[0, 0], [0, 0]])\n",
    "env = Environment(users0, products, secondary_dict, feature_matrix0, feature_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upper Bound for Cumulative Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_ts = TS_regret(env, 365, 1e-3)\n",
    "ub_ucb = ucb_regret(env, 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimal Reward e Optimal Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Aggregated User ----------------------------\n",
      "Aggregated Optimal Reward : 18.013 - Optimal Combination : [1, 1, 0, 2, 0]\n",
      "-------------------------- 3 classes Users ----------------------------\n",
      "Aggregated Optimal Reward : 23.214 VS Disaggregated Optimal Reward : 24.754\n",
      "Aggregated Optimal Price combination : [1, 1, 0, 1, 0]\n",
      "Optimal price combinations with users divided by category:\n",
      "Young and Not Expert - [1, 1, 0, 0, 0] - 8.546513\n",
      "Old and Not Expert - [1, 2, 2, 0, 0] - 23.074523\n",
      "Expert - [0, 1, 0, 2, 2] - 49.010367\n"
     ]
    }
   ],
   "source": [
    "aggr_opt_reward, aggr_opt_comb = env.optimal_reward()\n",
    "print('-------------------------- Aggregated User ----------------------------')\n",
    "print( 'Aggregated Optimal Reward : %.3f - Optimal Combination : %s' %(aggr_opt_reward, aggr_opt_comb))\n",
    "print('-------------------------- 3 classes Users ----------------------------')\n",
    "opt_rewards_array, opt_comb_list = env3.optimal_reward(Disaggregated=True)\n",
    "aggr_opt_reward, aggr_opt_comb = env3.optimal_reward()\n",
    "dis_opt_reward = np.sum(np.array(env3.user_cat_prob)*opt_rewards_array)\n",
    "print('Aggregated Optimal Reward : %.3f VS Disaggregated Optimal Reward : %.3f' %(aggr_opt_reward, dis_opt_reward))\n",
    "print('Aggregated Optimal Price combination : %s' %aggr_opt_comb)\n",
    "print('Optimal price combinations with users divided by category:')\n",
    "for i, user in enumerate(env3.users):\n",
    "    print('%s - %s - %f' %(user.category, str(opt_comb_list[i]), opt_rewards_array[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 : Greedy Algorithm Functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Reward and Optimal Combination found by Greedy optimizer:\n",
      "{'expected_reward': 19.470002473907506, 'combination': [1, 1, 0, 2, 0]}\n",
      "Thoeretica Optimal Reward and Optimal Combination:\n",
      "{expected_reward : 19.470002, combination : [1, 1, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "greedy_optimizer = Greedy_optimizer(env)\n",
    "print('Optimal Reward and Optimal Combination found by Greedy optimizer:')\n",
    "print(greedy_optimizer.run())\n",
    "print('Thoeretica Optimal Reward and Optimal Combination:')\n",
    "print('{expected_reward : %lf, combination : %s'%env.optimal_reward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Values found by the Greedy Optimizer\n",
      "Optimal Expected Rewards : [10.046397, 26.956458, 50.439718]\n",
      "Optimale Combinations: [[1, 1, 0, 0, 0], [0, 1, 2, 0, 0], [0, 0, 0, 2, 2]]\n",
      "Total Expected Reward : 26.899210\n",
      "\n",
      "Theoretical Optimal Values\n",
      "Optimal Expected Rewards : [10.046397, 26.956458, 50.439718]\n",
      "Optimale Combinations: [[1, 1, 0, 0, 0], [0, 1, 2, 0, 0], [0, 0, 0, 2, 2]]\n",
      "Total Expected Reward : 26.899210\n"
     ]
    }
   ],
   "source": [
    "greedy_3 = Greedy_optimizer(env3)\n",
    "greedy_3.run()\n",
    "\n",
    "rew0, comb0 = greedy_3.run(group_list=[[0,0]]).values()\n",
    "rew1, comb1 = greedy_3.run(group_list=[[0,1]]).values()\n",
    "rew2, comb2 = greedy_3.run(group_list=[[1,0], [1,1]]).values()\n",
    "print('Optimal Values found by the Greedy Optimizer')\n",
    "print('Optimal Expected Rewards : [%f, %f, %f]\\nOptimale Combinations: [%s, %s, %s]' %(rew0,rew1,rew2,comb0,comb1,comb2))\n",
    "print('Total Expected Reward : %f' %(np.sum(np.array((rew0,rew1,rew2))*env3.user_cat_prob)))\n",
    "print('\\nTheoretical Optimal Values')\n",
    "rewards, combinations = env3.optimal_reward(Disaggregated=True)\n",
    "print('Optimal Expected Rewards : [%f, %f, %f]' %(rewards[0], rewards[1], rewards[2]))\n",
    "print('Optimale Combinations: [%s, %s, %s]' %(combinations[0], combinations[1], combinations[2] ))\n",
    "print('Total Expected Reward : %f' %(np.sum(rewards*env3.user_cat_prob)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 : Uncertain Convertion Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a = np.ones((5,4))\n",
    "b = np.ones((5,4))\n",
    "initial_beta_CR = np.array([a, b])\n",
    "learner_TS3 = Step3_TS(env, initial_beta_CR, learning_rate = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for the algorithm execution\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365\n",
    "\n",
    "# delete possible old informations form past runs \n",
    "learner_TS3.reward_history = []\n",
    "learner_TS3.price_comb_history = []\n",
    "learner_TS3.cr_matrix_list = []\n",
    "\n",
    "# execute the algorithm n_runs times\n",
    "for i in range(n_runs) :\n",
    "    learner_TS3.run(n_days, daily_users)\n",
    "\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS3 = learner_TS3.opt_reward\n",
    "collected_rewards_TS3 = learner_TS3.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salvo la history su file in modo che siamo sicuri ti riuscire a recuperarla anche in un secondo momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step3_TS_NFC', 'wb') as f: \n",
    "    pickle.dump(learner_TS3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per recuperare, invece, i risultati ottenuti in un secondo momento :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step3_TS_NFC', 'rb') as f: \n",
    "    learner_TS3 = pickle.load(f)\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS3 = learner_TS3.opt_reward\n",
    "collected_rewards_TS3 = learner_TS3.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward_TS3 - collected_rewards_TS3, axis=0)), 'r') \n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward_TS3 - collected_rewards_TS3, axis=0), 'r')\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_R_TS3 = np.cumsum(opt_reward_TS3 - collected_rewards_TS3, axis = 1)\n",
    "mean_cum_R_TS3 = np.mean(cum_R_TS3, axis = 0)\n",
    "std_dev_TS3 = np.std(cum_R_TS3, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R_TS3)\n",
    "plt.fill_between(range(n_days), mean_cum_R_TS3-std_dev_TS3, mean_cum_R_TS3+std_dev_TS3, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward_TS3, color = 'green')\n",
    "plt.plot(np.mean(collected_rewards_TS3, axis=0))\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Expected Reward (t)\")\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ratio with respect to theoretical upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list_TS3 = mean_cum_R_TS3/ub_ts\n",
    "print('Last iteration Ratio is : %f' %ratio_list_TS3[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimation of Uncertain Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_CR_TS3 = np.mean(learner_TS3.cr_matrix_list, axis = 0)\n",
    "\n",
    "print('Conversion Rates:\\n%s' %str(mean_CR_TS3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('THEORETICAL VALUES:\\n\\nConversion Rates :\\n%s' %np.matrix(env.theoretical_values['conversion_rates'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the run parameters\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_reward = env.optimal_reward()[0]\n",
    "ucb3 = step3_ucb1(len(prices), len(prices[0]), prices, env)\n",
    "for _ in range(n_runs):\n",
    "    ucb3.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"./learners_file/ucb3_NFC\", 'wb') as f1:\n",
    "    pickle.dump(ucb3, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"./learners_file/ucb3_NFC\", 'rb') as f1:\n",
    "    ucb3 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x13fdebb20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step3_ucb1_collected_rewards = ucb3.collected_rewards\n",
    "step3_ucb1_R = ucb3.regret\n",
    "# plot of the result\n",
    "mean_step3_ucb1_R = np.mean(step3_ucb1_R, axis=0)\n",
    "std_dev_step3_ucb1 = np.std(step3_ucb1_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_step3_ucb1_R)\n",
    "plt.fill_between(range(n_days), mean_step3_ucb1_R-std_dev_step3_ucb1, mean_step3_ucb1_R+std_dev_step3_ucb1, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(step3_ucb1_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ratio with respect to theoretical upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last iteration Ratio is : 0.179512\n"
     ]
    }
   ],
   "source": [
    "ratio_list_ucb3 = mean_step3_ucb1_R/ub_ucb\n",
    "print('Last iteration Ratio is : %f' %ratio_list_ucb3[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last n pulled arms:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last n pulled arms\n",
    "print(\"Last n pulled arms:\")\n",
    "np.array(ucb3.pulled[-10:-1], dtype=np.int32)[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/kqvbs5qd1cqf0h0mq7jcbl_m0000gn/T/ipykernel_7058/3716341339.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result.append(x[np.argmax(np.array(x)[:, 1])])\n",
      "/var/folders/1q/kqvbs5qd1cqf0h0mq7jcbl_m0000gn/T/ipykernel_7058/3716341339.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/function_base.py:5030: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal arms combination:\n",
      "[1, 1, 0, 2, 0] 18.013187637352548\n",
      "\n",
      "\n",
      "Ucb1 most pulled arms:\n",
      "(arms combination), (n° pulls), (exp rew)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[1, 1, 0, 2, 0], 156, 18.013187637352548],\n",
       " [[2, 1, 0, 2, 0], 118, 17.95435433003422],\n",
       " [[1, 2, 0, 2, 0], 24, 17.881812015925235],\n",
       " [[2, 2, 0, 2, 0], 23, 17.824657396299127],\n",
       " [[1, 1, 1, 2, 0], 7, 17.536024386865805],\n",
       " [[3, 3, 3, 3, 3], 6, 2.48121055089595],\n",
       " [[2, 1, 1, 2, 0], 4, 17.477191079547474],\n",
       " [[2, 2, 2, 2, 1], 4, 15.352294658603629],\n",
       " [[2, 1, 1, 2, 1], 3, 16.36119730143635],\n",
       " [[2, 2, 1, 2, 1], 3, 16.231500367701255],\n",
       " [[2, 2, 2, 2, 2], 3, 11.083814974216741],\n",
       " [[3, 1, 0, 2, 0], 3, 17.579945056131717],\n",
       " [[3, 2, 1, 2, 1], 2, 15.883041126744583],\n",
       " [[1, 1, 1, 2, 1], 1, 16.420030608754672],\n",
       " [[2, 1, 0, 2, 1], 1, 16.822287123471085],\n",
       " [[2, 2, 0, 2, 1], 1, 16.69259018973599],\n",
       " [[2, 2, 1, 2, 0], 1, 17.347494145812384],\n",
       " [[3, 1, 0, 2, 1], 1, 16.447877849568577],\n",
       " [[3, 1, 1, 2, 1], 1, 15.986788027533843],\n",
       " [[3, 2, 2, 2, 2], 1, 10.735355733260072]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ucb1 most pulled arms\n",
    "combinations_data = [[] for i in range(1024)]\n",
    "for i1 in range(4):\n",
    "    for i2 in range(4):\n",
    "        for i3 in range(4):\n",
    "            for i4 in range(4):\n",
    "                for i5 in range(4):\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append([i1, i2, i3, i4, i5])\n",
    "                    c = np.array(np.array(ucb3.pulled, dtype=np.int32)[:, 0].tolist()) == [i1, i2, i3, i4, i5]\n",
    "                    c = np.prod(c, axis=1)\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(np.count_nonzero(c))\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(env.expected_reward([i1, i2, i3, i4, i5]))\n",
    "                    x = combinations_data\n",
    "result = []\n",
    "for i in range(20):\n",
    "    result.append(x[np.argmax(np.array(x)[:, 1])])\n",
    "    x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n",
    "print(\"Optimal arms combination:\")\n",
    "print(env.optimal_reward()[1], env.optimal_reward()[0])\n",
    "print(\"\\n\\nUcb1 most pulled arms:\")\n",
    "print(\"(arms combination), (n° pulls), (exp rew)\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rates estimation (means + widths, over n experiments):\n",
      " [[1.         0.65352949 0.46508822 0.33610808]\n",
      " [1.         0.76748401 0.56315613 0.16080497]\n",
      " [0.85835103 0.76215218 0.6124634  0.22332764]\n",
      " [1.         1.         0.96162589 0.34547347]\n",
      " [0.80695706 0.74528248 0.37436646 0.18523947]]\n"
     ]
    }
   ],
   "source": [
    "ucb3.print_estimations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 : Uncertain conversion rates, alpha ratio and number of products sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a = np.ones((5,4))\n",
    "b = np.ones((5,4))\n",
    "initial_beta_CR = np.array([a, b])\n",
    "initial_beta_alpha = np.ones((2,5))\n",
    "initial_n_prod_data = np.ones((2,5))\n",
    "learner_TS4 = Step4_TS(env, initial_beta_CR, initial_beta_alpha, initial_n_prod_data, learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for the algorithm execution\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365\n",
    "\n",
    "# delete possible old informations form past runs \n",
    "learner_TS4.reward_history = []\n",
    "learner_TS4.price_comb_history = []\n",
    "learner_TS4.cr_matrix_list = []\n",
    "learner_TS4.alpha_ratios_list = []\n",
    "learner_TS4.n_prod_list = []\n",
    "\n",
    "# execute the algorithm n_runs times\n",
    "for i in range(n_runs) :\n",
    "    learner_TS4.run(n_days, daily_users)\n",
    "\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS4 = learner_TS4.opt_reward\n",
    "collected_rewards_TS4 = learner_TS4.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salvo la history su file in modo che siamo sicuri ti riuscire a recuperarla anche in un secondo momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step4_TS_NFC', 'wb') as f: \n",
    "    pickle.dump(learner_TS4, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per recuperare, invece, i risultati ottenuti in un secondo momento :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step4_TS_NFC', 'rb') as f: \n",
    "    learner_TS4 = pickle.load(f)\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS4 = learner_TS4.opt_reward\n",
    "collected_rewards_TS4 = learner_TS4.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward_TS4 - collected_rewards_TS4, axis=0)), 'r')\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward_TS4 - collected_rewards_TS4, axis=0), 'r')\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_R_TS4 = np.cumsum(opt_reward_TS4 - collected_rewards_TS4, axis = 1)\n",
    "mean_cum_R_TS4 = np.mean(cum_R_TS4, axis = 0)\n",
    "std_dev_TS4 = np.std(cum_R_TS4, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R_TS4)\n",
    "plt.fill_between(range(n_days), mean_cum_R_TS4-std_dev_TS4, mean_cum_R_TS4+std_dev_TS4, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward_TS4, color = 'green')\n",
    "plt.plot(np.mean(collected_rewards_TS4, axis=0))\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Expected Reward (t)\")\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ratio with respect to theoretical upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list_TS4 = mean_cum_R_TS4/ub_ts\n",
    "print('Last iteration Ratio is : %f' %ratio_list_TS4[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimation of Uncertain Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_alpha_TS4 = np.mean(np.array(learner_TS4.alpha_ratios_list), axis = 0)\n",
    "mean_n_prod_TS4 = np.mean(np.array(learner_TS4.n_prod_list), axis = 0)\n",
    "mean_CR_TS4 = np.mean(learner_TS4.cr_matrix_list, axis = 0)\n",
    "\n",
    "print('Conversion Rates:\\n%s' %mean_CR_TS4)\n",
    "print('\\nAlpha Ratios : %s' % mean_alpha_TS4)\n",
    "print('\\nMean Number of product sold : %s' %mean_n_prod_TS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('THEORETICAL VALUES:\\n\\nConversion Rates :\\n%s' %np.matrix(env.theoretical_values['conversion_rates'][0]))\n",
    "print('\\nAlpha Ratios : %s' %env.alpha_ratios[0] )\n",
    "print('\\nMean Number of product sold : %s' %(env.users[0].poisson_lambda+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the run parameters\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/OLA/OLA2022project/step4_ucb1.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "  alphas_ratio = np.divide(np.sum([self.alphas_means, self.alphas_widths], axis=0), np.sum([self.alphas_means, self.alphas_widths]))\n"
     ]
    }
   ],
   "source": [
    "opt_reward = env.optimal_reward()[0]\n",
    "ucb4 = step4_ucb1(len(prices), len(prices[0]), prices, env)\n",
    "for _ in range(n_runs):\n",
    "    ucb4.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"./learners_file/ucb4_NFC\", 'wb') as f1:\n",
    "    pickle.dump(ucb4, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"./learners_file/ucb4_NFC\", 'rb') as f1:\n",
    "    ucb4 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x16848a800>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step4_ucb1_collected_rewards = ucb4.collected_rewards\n",
    "step4_ucb1_R = ucb4.regret\n",
    "# plot of the result\n",
    "mean_step4_ucb1_R = np.mean(step4_ucb1_R, axis=0)\n",
    "std_dev_step4_ucb1 = np.std(step4_ucb1_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_step4_ucb1_R)\n",
    "plt.fill_between(range(n_days), mean_step4_ucb1_R-std_dev_step4_ucb1, mean_step4_ucb1_R+std_dev_step4_ucb1, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(step4_ucb1_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ratio with respect to theoretical upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last iteration Ratio is : 0.178109\n"
     ]
    }
   ],
   "source": [
    "ratio_list_ucb4 = mean_step4_ucb1_R/ub_ucb\n",
    "print('Last iteration Ratio is : %f' %ratio_list_ucb4[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last n pulled arms:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0],\n",
       " [1, 1, 0, 2, 0]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last n pulled arms\n",
    "print(\"Last n pulled arms:\")\n",
    "np.array(ucb4.pulled[-10:-1], dtype=np.int32)[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/kqvbs5qd1cqf0h0mq7jcbl_m0000gn/T/ipykernel_7058/3715184616.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result.append(x[np.argmax(np.array(x)[:, 1])])\n",
      "/var/folders/1q/kqvbs5qd1cqf0h0mq7jcbl_m0000gn/T/ipykernel_7058/3715184616.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal arms combination:\n",
      "[1, 1, 0, 2, 0] 18.013187637352548\n",
      "\n",
      "\n",
      "Ucb1 most pulled arms:\n",
      "(arms combination), (n° pulls), (exp rew)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[2, 1, 0, 2, 0], 218, 17.95435433003422],\n",
       " [[1, 1, 0, 2, 0], 103, 18.013187637352548],\n",
       " [[1, 2, 0, 2, 0], 14, 17.881812015925235],\n",
       " [[2, 2, 1, 2, 1], 5, 16.231500367701255],\n",
       " [[2, 2, 2, 2, 1], 5, 15.352294658603629],\n",
       " [[3, 3, 3, 3, 3], 5, 2.48121055089595],\n",
       " [[3, 1, 0, 2, 0], 4, 17.579945056131717],\n",
       " [[2, 1, 1, 2, 0], 2, 17.477191079547474],\n",
       " [[2, 2, 1, 2, 0], 2, 17.347494145812384],\n",
       " [[2, 2, 0, 2, 0], 1, 17.824657396299127],\n",
       " [[2, 2, 2, 3, 2], 1, 6.648785611244051],\n",
       " [[3, 1, 1, 2, 0], 1, 17.102781805644973],\n",
       " [[3, 2, 1, 2, 1], 1, 15.883041126744583],\n",
       " [[3, 2, 2, 3, 2], 1, 6.300326370287381],\n",
       " [[3, 2, 3, 3, 2], 1, 4.868131898577455],\n",
       " [[3, 3, 2, 3, 2], 1, 5.48169438585106],\n",
       " [[0, 0, 0, 0, 0], 0, 16.048414279416992],\n",
       " [[0, 0, 0, 0, 1], 0, 14.952117176133536],\n",
       " [[0, 0, 0, 0, 2], 0, 10.629241409105127],\n",
       " [[0, 0, 0, 0, 3], 0, 8.357563598189172]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ucb1 most pulled arms\n",
    "combinations_data = [[] for i in range(1024)]\n",
    "for i1 in range(4):\n",
    "    for i2 in range(4):\n",
    "        for i3 in range(4):\n",
    "            for i4 in range(4):\n",
    "                for i5 in range(4):\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append([i1, i2, i3, i4, i5])\n",
    "                    c = np.array(np.array(ucb4.pulled, dtype=np.int32)[:, 0].tolist()) == [i1, i2, i3, i4, i5]\n",
    "                    c = np.prod(c, axis=1)\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(np.count_nonzero(c))\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(env.expected_reward([i1, i2, i3, i4, i5]))\n",
    "                    x = combinations_data\n",
    "result = []\n",
    "for i in range(20):\n",
    "    result.append(x[np.argmax(np.array(x)[:, 1])])\n",
    "    x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n",
    "print(\"Optimal arms combination:\")\n",
    "print(env.optimal_reward()[1], env.optimal_reward()[0])\n",
    "print(\"\\n\\nUcb1 most pulled arms:\")\n",
    "print(\"(arms combination), (n° pulls), (exp rew)\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated alpha ratios (means + widths, over n experiments):\n",
      " [0.2099285  0.2095816  0.20978589 0.20874165 0.20902919] \n",
      "\n",
      "Estimated number of products sold (means + widths, over n experiments):\n",
      " [2.5101396  1.98735661 1.50265606 1.40759179 1.19573006] \n",
      "\n",
      "\n",
      "Conversion rates estimation (means + widths, over n experiments):\n",
      " [[1.         0.6545133  0.46569919 0.33853855]\n",
      " [1.         0.7669189  0.56383745 0.16835083]\n",
      " [0.85833655 0.76198533 0.61102962 0.22374177]\n",
      " [1.         1.         0.96151634 0.34517418]\n",
      " [0.80650341 0.74564769 0.37966423 0.18550514]]\n"
     ]
    }
   ],
   "source": [
    "ucb4.print_estimations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 : Uncertain conversion rates and graph weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a_cr = np.ones((5,4))\n",
    "b_cr = np.ones((5,4))\n",
    "initial_beta_CR = np.array([a_cr, b_cr])\n",
    "a_gw = np.ones((5,2))\n",
    "b_gw = np.ones((5,2))\n",
    "initial_beta_gw = np.array([a_gw, b_gw])\n",
    "learner_TS5 = Step5_TS(env, initial_beta_CR, initial_beta_gw, learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for the algorithm execution\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365\n",
    "\n",
    "# delete possible old informations form past runs \n",
    "learner_TS5.reward_history = []\n",
    "learner_TS5.price_comb_history = []\n",
    "learner_TS5.cr_matrix_list = []\n",
    "learner_TS5.graph_weights_list = []\n",
    "\n",
    "# execute the algorithm n_runs times\n",
    "for i in range(n_runs) :\n",
    "    learner_TS5.run(n_days, daily_users)\n",
    "\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS5 = learner_TS5.opt_reward\n",
    "collected_rewards_TS5 = learner_TS5.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salvo la history su file in modo che siamo sicuri ti riuscire a recuperarla anche in un secondo momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step5_TS_NFC', 'wb') as f: \n",
    "    pickle.dump(learner_TS5, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Per recuperare, invece, i risultati ottenuti in un secondo momento :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step5_TS_NFC', 'rb') as f: \n",
    "    learner_TS5 = pickle.load(f)\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS5 = learner_TS5.opt_reward\n",
    "collected_rewards_TS5 = learner_TS5.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward_TS5 - collected_rewards_TS5, axis=0)), 'r')\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward_TS5 - collected_rewards_TS5, axis=0), 'r')  \n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_R_TS5 = np.cumsum(opt_reward_TS5 - collected_rewards_TS5, axis = 1)\n",
    "mean_cum_R_TS5 = np.mean(cum_R_TS5, axis = 0)\n",
    "std_dev_TS5 = np.std(cum_R_TS5, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R_TS5)\n",
    "plt.fill_between(range(n_days), mean_cum_R_TS5-std_dev_TS5, mean_cum_R_TS5+std_dev_TS5, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward_TS5, color = 'green')\n",
    "plt.plot(np.mean(collected_rewards_TS5, axis=0))\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Expected Reward (t)\")\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ratio with respect to theoretical upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list_TS5 = mean_cum_R_TS5/ub_ts\n",
    "print('Last iteration Ratio is : %f' %ratio_list_TS5[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimation of Uncertain Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_CR_TS5 = np.mean(learner_TS5.cr_matrix_list, axis = 0)\n",
    "mean_GW_TS5 = np.mean(learner_TS5.graph_weights_list, axis = 0)\n",
    "\n",
    "print('Conversion Rates:\\n%s' %mean_CR_TS5)\n",
    "print('\\nGraph Weights : %s' %mean_GW_TS5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('THEORETICAL VALUES:\\n\\nConversion Rates :\\n%s' %np.matrix(env.theoretical_values['conversion_rates'][0]))\n",
    "print('\\nGraph Weights :\\n%s' %env.users[0].probabilities )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the run parameters\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andre/OLA/OLA2022project/NOT_Fully_Con.ipynb Cella 109\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andre/OLA/OLA2022project/NOT_Fully_Con.ipynb#Y213sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ucb5 \u001b[39m=\u001b[39m step5_ucb1(\u001b[39mlen\u001b[39m(prices), \u001b[39mlen\u001b[39m(prices[\u001b[39m0\u001b[39m]), prices, env)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andre/OLA/OLA2022project/NOT_Fully_Con.ipynb#Y213sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_runs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andre/OLA/OLA2022project/NOT_Fully_Con.ipynb#Y213sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     ucb5\u001b[39m.\u001b[39;49mrun(n_days, daily_users)\n",
      "File \u001b[0;32m~/OLA/OLA2022project/step5_ucb1.py:66\u001b[0m, in \u001b[0;36mstep5_ucb1.run\u001b[0;34m(self, n_days, daily_users)\u001b[0m\n\u001b[1;32m     64\u001b[0m visualizations \u001b[39m=\u001b[39m day_data[\u001b[39m\"\u001b[39m\u001b[39mvisualizations\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     65\u001b[0m clicks \u001b[39m=\u001b[39m day_data[\u001b[39m\"\u001b[39m\u001b[39mclicks\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(pulled_arms, cr_data, n_users, visualizations, clicks)\n\u001b[1;32m     67\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mexpected_reward(pulled_arms)\n\u001b[1;32m     68\u001b[0m collected_rewards_temp\u001b[39m.\u001b[39mappend(reward)\n",
      "File \u001b[0;32m~/OLA/OLA2022project/step5_ucb1.py:47\u001b[0m, in \u001b[0;36mstep5_ucb1.update\u001b[0;34m(self, arms_pulled, cr_data, n_users, visualizations, clicks)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m product_idx_1 \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_products):\n\u001b[1;32m     45\u001b[0m     \u001b[39mfor\u001b[39;00m product_idx_2 \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_products):\n\u001b[1;32m     46\u001b[0m         \u001b[39m# total number of samples on the secondary product [product_idx_2] for [prod_idx_1] as primary\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m         n \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39;49marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_data)[:, \u001b[39m1\u001b[39m][:, product_idx_1, product_idx_2])\n\u001b[1;32m     48\u001b[0m         \u001b[39mif\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     49\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_weights_widths[product_idx_1, product_idx_2] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mdivide(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(graph_weights_t), (n \u001b[39m*\u001b[39m (graph_weights_t \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt_reward = env.optimal_reward()[0]\n",
    "ucb5 = step5_ucb1(len(prices), len(prices[0]), prices, env)\n",
    "for _ in range(n_runs):\n",
    "    ucb5.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"./learners_file/ucb5_NFC\", 'wb') as f1:\n",
    "    pickle.dump(ucb5, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"./learners_file/ucb5_NFC\", 'rb') as f1:\n",
    "    ucb5 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step5_ucb1_collected_rewards = ucb5.collected_rewards\n",
    "step5_ucb1_R = ucb5.regret\n",
    "# plot of the result\n",
    "mean_step5_ucb1_R = np.mean(step5_ucb1_R, axis=0)\n",
    "std_dev_step5_ucb1 = np.std(step5_ucb1_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_step5_ucb1_R)\n",
    "plt.fill_between(range(n_days), mean_step5_ucb1_R-std_dev_step5_ucb1, mean_step5_ucb1_R+std_dev_step5_ucb1, alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(step5_ucb1_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ratio with respect to theoretical upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list_ucb5 = mean_step5_ucb1_R/ub_ucb\n",
    "print('Last iteration Ratio is : %f' %ratio_list_ucb5[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last n pulled arms\n",
    "print(\"Last n pulled arms:\")\n",
    "np.array(ucb5.pulled[-10:-1], dtype=np.int32)[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ucb1 most pulled arms\n",
    "combinations_data = [[] for i in range(1024)]\n",
    "for i1 in range(4):\n",
    "    for i2 in range(4):\n",
    "        for i3 in range(4):\n",
    "            for i4 in range(4):\n",
    "                for i5 in range(4):\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append([i1, i2, i3, i4, i5])\n",
    "                    c = np.array(np.array(ucb5.pulled, dtype=np.int32)[:, 0].tolist()) == [i1, i2, i3, i4, i5]\n",
    "                    c = np.prod(c, axis=1)\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(np.count_nonzero(c))\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(env.expected_reward([i1, i2, i3, i4, i5]))\n",
    "                    x = combinations_data\n",
    "result = []\n",
    "for i in range(20):\n",
    "    result.append(x[np.argmax(np.array(x)[:, 1])])\n",
    "    x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n",
    "print(\"Optimal arms combination:\")\n",
    "print(env.optimal_reward()[1], env.optimal_reward()[0])\n",
    "print(\"\\n\\nUcb1 most pulled arms:\")\n",
    "print(\"(arms combination), (n° pulls), (exp rew)\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb5.print_estimations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6 : Abrupt Changes in Demand Curve with Uncertain Conversion Rates and Graph Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Abrupt Changes Setting Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# ABRUPT CHANGE SETTING #\n",
    "#########################\n",
    "n_days = 365\n",
    "\n",
    "# We suppose to start in September, with relative high demand. Our hypothesis is that every season we have an\n",
    "# abrupt change in demand curve\n",
    "changes_dict ={ # BASE CASE: AUTUMN\n",
    "    90 : {\"mean\": [10.1, 13.8, 23.2, 36.4, 43.7], \"std\": [3, 1.5, 2, 2.5, 2.5]}, # WINTER\n",
    "    180 : {\"mean\": [9, 13, 22, 35, 42], \"std\": [3, 1.5, 2, 2.5, 2.5]}, # SPRING\n",
    "    270 : {\"mean\": [8.2, 11.7, 20.5, 31.6, 39.1], \"std\": [3, 1.5, 2, 2.5, 2.5]} # SUMMER\n",
    "}\n",
    "opt_reward = env.optimal_reward()[0]\n",
    "opt_reward_evolution = np.zeros(n_days)\n",
    "original_res_price_param = copy.deepcopy(env.users[0].res_price_params)\n",
    "for t in range(n_days):\n",
    "    if t in changes_dict.keys(): \n",
    "        env.abrupt_change_deterministic([changes_dict[t]])\n",
    "        opt_reward = env.optimal_reward()[0]\n",
    "    opt_reward_evolution[t] = opt_reward\n",
    "\n",
    "env.abrupt_change_deterministic([original_res_price_param])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - SW UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 100\n",
    "daily_users = 100\n",
    "\n",
    "sw = int(3*np.sqrt(n_days))\n",
    "sw_ucb = step6_sw_ucb(len(prices), len(prices[0]), prices, env, changes_dict, sw)\n",
    "for _ in range(n_runs):\n",
    "    sw_ucb.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"./learners_file/sw_ucb_NFC\", 'wb') as f1:\n",
    "    pickle.dump(sw_ucb, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"./learners_file/sw_ucb_NFC\", 'rb') as f1:\n",
    "    sw_ucb = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_ucb_collected_rewards = sw_ucb.collected_rewards\n",
    "sw_ucb_R = sw_ucb.regret\n",
    "# plot of the result\n",
    "mean_sw_ucb_R = np.mean(sw_ucb_R, axis=0)\n",
    "std_sw_ucb = np.std(sw_ucb_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_sw_ucb_R)\n",
    "plt.fill_between(range(n_days), mean_sw_ucb_R-std_sw_ucb, mean_sw_ucb_R+std_sw_ucb, alpha=0.4)\n",
    "changes_time = list(changes_dict.keys())\n",
    "changes_n = len(changes_time)\n",
    "plt.vlines(changes_time, [0]*changes_n, [max(mean_sw_ucb_R)]*changes_n, color = 'red', label= 'changes time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.plot(opt_reward_evolution, color = 'green')\n",
    "plt.plot(np.mean(sw_ucb_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Change Detection UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change detection hyper parameters\n",
    "m = 50\n",
    "eps = 0.02\n",
    "h = 0.3\n",
    "cd_ucb = Step6_CD(len(prices), len(prices[0]), prices, env, changes_dict, m, eps, h)\n",
    "# run setting (n_days fixed before)\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    cd_ucb.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"./learners_file/cd_ucb_NFC\", 'wb') as f1:\n",
    "    pickle.dump(cd_ucb, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"./learners_file/cd_ucb_NFC\", 'rb') as f1:\n",
    "    cd_ucb = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_ucb_collected_rewards = cd_ucb.collected_rewards\n",
    "cd_ucb_R = cd_ucb.regret\n",
    "# plot of the result\n",
    "mean_cd_ucb_R = np.mean(cd_ucb_R, axis=0)\n",
    "std_cd_ucb = np.std(cd_ucb_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(mean_cd_ucb_R)\n",
    "plt.fill_between(range(n_days), mean_cd_ucb_R-std_cd_ucb, mean_cd_ucb_R+std_cd_ucb, alpha=0.4)\n",
    "changes_time = list(changes_dict.keys())\n",
    "changes_n = len(changes_time)\n",
    "plt.vlines(changes_time, [0]*changes_n, [max(mean_cd_ucb_R)]*changes_n, color = 'red', label= 'changes time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.plot(opt_reward_evolution, color = 'green')\n",
    "plt.plot(np.mean(cd_ucb_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7 : Context generation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a = np.ones((5,4))\n",
    "b = np.ones((5,4))\n",
    "initial_beta_CR = np.array([a, b])\n",
    "initial_beta_alpha = np.ones((2,5))\n",
    "initial_n_prod_data = np.ones((2,5))\n",
    "cg_confidence = 0.05\n",
    "learner_TS7 = Step7_TS(env3, initial_beta_CR, initial_beta_alpha, initial_n_prod_data, cg_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for the algorithm execution\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365\n",
    "\n",
    "# delete possible old informations form past runs \n",
    "learner_TS7.reward_history = []\n",
    "learner_TS7.context_history = []\n",
    "\n",
    "# execute the algorithm n_runs times\n",
    "for i in range(n_runs) :\n",
    "    learner_TS7.run(n_days, daily_users)\n",
    "\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS7 = learner_TS7.opt_reward\n",
    "collected_rewards_TS7 = learner_TS7.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salvo la history su file in modo che siamo sicuri ti riuscire a recuperarla anche in un secondo momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step7_TS_NFC', 'wb') as f: \n",
    "    pickle.dump(learner_TS7, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per recuperare, invece, i risultati ottenuti in un secondo momento :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./learners_file/step7_TS_NFC', 'rb') as f: \n",
    "    learner_TS7 = pickle.load(f)\n",
    "# collect all informations for the plot\n",
    "opt_reward_TS7 = learner_TS7.opt_reward\n",
    "collected_rewards_TS7 = learner_TS7.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward_TS7 - collected_rewards_TS7, axis=0)), 'r')\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward_TS7 - collected_rewards_TS7, axis=0), 'r') \n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_R_TS7 = np.cumsum(opt_reward_TS7 - collected_rewards_TS7, axis = 1)\n",
    "mean_cum_R_TS7 = np.mean(cum_R_TS7, axis = 0)\n",
    "std_dev_TS7 = np.std(cum_R_TS7, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R_TS7)\n",
    "plt.fill_between(range(n_days), mean_cum_R_TS7-std_dev_TS7, mean_cum_R_TS7+std_dev_TS7, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward_TS7, color = 'green')\n",
    "plt.axhline(aggr_opt_reward, color = 'red')\n",
    "plt.plot(np.mean(collected_rewards_TS7, axis=0))\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Expected Reward (t)\")\n",
    "plt.legend([\"Optimal Reward\",\"Aggregated Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the run parameters\n",
    "n_runs = 100\n",
    "daily_users = 100\n",
    "n_days = 365\n",
    "\n",
    "confidence = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb7 = step7_ucb1(len(prices), len(prices[0]), prices, env3, confidence)\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    ucb7.run(n_days, daily_users)\n",
    "\n",
    "opt_reward_ucb7 = ucb7.opt_reward\n",
    "collected_rewards_ucb7 = ucb7.reward_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"./learners_file/ucb7_NFC\", 'wb') as f1:\n",
    "    pickle.dump(ucb7, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"./learners_file/ucb7_NFC\", 'rb') as f1:\n",
    "    ucb7 = pickle.load(f1)\n",
    "# collect all informations for the plot\n",
    "opt_reward_ucb7 = ucb7.opt_reward\n",
    "collected_rewards_ucb7 = ucb7.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward_ucb7 - collected_rewards_ucb7, axis=0)), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "plt.legend([\"UCB1\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward_ucb7 - collected_rewards_ucb7, axis=0), 'r')\n",
    "plt.legend([\"UCB1\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_R_ucb7 = np.cumsum(opt_reward_ucb7 - collected_rewards_ucb7, axis = 1)\n",
    "mean_cum_R_ucb7 = np.mean(cum_R_ucb7, axis = 0)\n",
    "std_dev_ucb7 = np.std(cum_R_ucb7, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R_ucb7)\n",
    "plt.fill_between(range(n_days), mean_cum_R_ucb7-std_dev_ucb7, mean_cum_R_ucb7+std_dev_ucb7, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward_ucb7, color = 'green')\n",
    "plt.axhline(aggr_opt_reward, color = 'red')\n",
    "plt.plot(np.mean(collected_rewards_ucb7, axis=0))\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Expected Reward (t)\")\n",
    "plt.legend([\"Optimal Reward\",\"Aggregated Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
