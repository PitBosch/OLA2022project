{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Environment import Environment\n",
    "from UserCat import UserCat\n",
    "from Product import Product\n",
    "from Greedy_optimizer import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ucb1_brute_force import *\n",
    "from ucb1_greedy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT DEFINITION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Environment fixed informations and Products definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "products=[]\n",
    "\n",
    "nameofproduct= [ #name of products\n",
    "    \"Calabazas\",\n",
    "    \"Hinojo\",\n",
    "    \"Sesamo\",\n",
    "    \"Girasol\",\n",
    "    \"Amapola\"\n",
    "]\n",
    "# Dictionary fixing the secondary products linked to \n",
    "secondary_dict= {        \n",
    "    \"Calabazas\": [1,2],\n",
    "    \"Hinojo\": [0,2],\n",
    "    \"Sesamo\": [1,3],\n",
    "    \"Girasol\": [2,4],\n",
    "    \"Amapola\": [2,3]\n",
    "}\n",
    "# Matrix n_prod*n_prices collecting the possible prices for each product. Prices are in ascending order\n",
    "prices = [[8., 9, 10, 11],\n",
    "          [10., 12, 14, 16],\n",
    "          [20., 22, 24, 26],\n",
    "          [28., 30, 32, 34],\n",
    "          [40., 42, 44, 46]]\n",
    "# Production cost of the products\n",
    "cost = [1.3, 1.8, 2.1, 3.5, 6]\n",
    "\n",
    "#sarebbe interessante anche prendere da file il tutto così da cambiare tutto più facilmente\n",
    "#calcolo i margini dai cost mi sembra più sensato e anche più veloce se dobbiamo cambiare continuamente\n",
    "# Computation of margins linked to each product for a particular choice of price\n",
    "cost2 = np.tile(np.array([cost]).transpose(), (1, 4))\n",
    "margins = np.array(prices)-cost2\n",
    "# Creation of the 5 objects of Product class\n",
    "for i in range (5):\n",
    "    products.append(Product(prices[i], i, nameofproduct[i],margins[i]))\n",
    "\n",
    "# Parameter for the computation of the click probability on the SECOND secondary product\n",
    "lambda_q = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 1: Young and Inexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_1 = {\n",
    "    \"mean\": [12, 15, 20, 25, 35],  \n",
    "    \"std\": [1, 1, 1, 1.5, 2]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_1 = [[0, 0.6, 0.3, 0, 0],\n",
    "                 [0.4, 0, 0.5, 0, 0],\n",
    "                 [0, 0.5, 0, 0.5, 0],\n",
    "                 [0, 0, 0.6, 0, 0.5],\n",
    "                 [0, 0, 0.3, 0.5, 0]]\n",
    "probabilities_1 = np.matrix(probabilities_1)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling \n",
    "alphas_1 = [15, 15, 10, 5, 5]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1 \n",
    "poisson_lambda_1 = 3\n",
    "\n",
    "user1 = UserCat(alphas_1, res_price_params_1, poisson_lambda_1, probabilities_1, category='young')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 2: Old and Inexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_2 = {\n",
    "    \"mean\": [9, 15, 30, 37, 45],  \n",
    "    \"std\": [1, 1.5, 2, 2, 1.5]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_2 = [[0, 0.6, 0.3, 0, 0],\n",
    "                 [0.4, 0, 0.5, 0, 0],\n",
    "                 [0, 0.5, 0, 0.5, 0],\n",
    "                 [0, 0, 0.6, 0, 0.5],\n",
    "                 [0, 0, 0.3, 0.5, 0]]\n",
    "probabilities_2 = np.matrix(probabilities_1)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling \n",
    "alphas_2 = [7, 12, 12, 12, 7]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1 \n",
    "poisson_lambda_2 = 3\n",
    "\n",
    "user2 = UserCat(alphas_2, res_price_params_2, poisson_lambda_2, probabilities_2, category='old')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 3: Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_3 = {\n",
    "    \"mean\": [8, 10, 30, 40, 49],  \n",
    "    \"std\": [1, 1, 1, 1.5, 2]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_3 = [[0, 0.6, 0.3, 0, 0],\n",
    "                 [0.4, 0, 0.5, 0, 0],\n",
    "                 [0, 0.5, 0, 0.5, 0],\n",
    "                 [0, 0, 0.6, 0, 0.5],\n",
    "                 [0, 0, 0.3, 0.5, 0]]\n",
    "probabilities_3 = np.matrix(probabilities_1)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling \n",
    "alphas_3 = [5, 5, 10, 15, 15]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1 \n",
    "poisson_lambda_3 = 3\n",
    "\n",
    "user3 = UserCat(alphas_3, res_price_params_3, poisson_lambda_3, probabilities_3, category='expert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 0: Aggregated demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_0 = {\n",
    "    \"mean\": [9, 10, 18, 27, 38],  \n",
    "    \"std\": [2, 3, 3, 3, 4]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_0 = [[0, 0.6, 0.3, 0, 0],\n",
    "                 [0.4, 0, 0.5, 0, 0],\n",
    "                 [0, 0.5, 0, 0.5, 0],\n",
    "                 [0, 0, 0.6, 0, 0.5],\n",
    "                 [0, 0, 0.3, 0.5, 0]]\n",
    "probabilities_0 = np.matrix(probabilities_1)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling \n",
    "alphas_0 = [10, 10, 10, 10, 10]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1 \n",
    "poisson_lambda_0 = 2\n",
    "\n",
    "user0 = UserCat(alphas_0, res_price_params_0, poisson_lambda_0, probabilities_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [[8., 9, 10, 11],\n",
    "          [10., 12, 14, 16],\n",
    "          [20., 22, 24, 26],\n",
    "          [28., 30, 32, 34],\n",
    "          [40., 42, 44, 46]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Environment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of users \n",
    "#users = [user1, user2, user3]\n",
    "users = [user0]\n",
    "# probability distribution of the users\n",
    "#p_users = [1/3, 1/3, 1/3]\n",
    "p_users = [1]\n",
    "\n",
    "env = Environment(users, products, lambda_q, secondary_dict, p_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.964988472960247, [0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.optimal_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.702358103541995"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.expected_reward([2,3,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark conversion rates matrix for aggregated demand curve\n",
    "np.matrix([[0.2, 0.19, 0.175, 0.155, 0.13],\n",
    "            [0.2, 0.19, 0.175, 0.155, 0.13],\n",
    "            [0.2, 0.19, 0.175, 0.155, 0.13],\n",
    "            [0.15, 0.14, 0.1275, 0.11, 0.09],\n",
    "            [0.1, 0.09, 0.0775, 0.065, 0.05]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [[8., 9, 10, 11],\n",
    "          [10., 12, 14, 16],\n",
    "          [20., 22, 24, 26],\n",
    "          [28., 30, 32, 34],\n",
    "          [40., 42, 44, 46]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1263911290388007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_norm = scipy.stats.norm()\n",
    "std_norm.ppf(0.2)\n",
    "std_norm.ppf(0.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.69146246, 0.5       , 0.30853754, 0.15865525],\n",
       "        [0.5       , 0.25249254, 0.09121122, 0.02275013],\n",
       "        [0.25249254, 0.09121122, 0.02275013, 0.00383038],\n",
       "        [0.36944134, 0.15865525, 0.04779035, 0.00981533],\n",
       "        [0.30853754, 0.15865525, 0.0668072 , 0.02275013]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix(env.theoretical_values['conversion_rates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "a = env.simulate_day(2000, [0,0,0,0,0], [\"conversion_rates\", \"alpha_ratios\", \"products_sold\", \"graph_weights\"])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "a = env.simulate_day(2000, [0,0,0,0,0], [\"conversion_rates\", \"alpha_ratios\", \"products_sold\", \"graph_weights\"], aggregated= False)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reservation Price Distribution Plot for one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = 0\n",
    "x = np.arange(0, 60 , .01)\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "color_list = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "for i in range(5):\n",
    "    res_price_distr = env.users[user_index].res_price_distr[i]\n",
    "    y = res_price_distr.pdf(x)\n",
    "    plt.plot(x, y, label = 'Product %d' %i, color = color_list[i])\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        plt.scatter(prices[i][j], 0.025, color = color_list[i])\n",
    "\n",
    "plt.title(\"Reservation Price Distributions for the user category %s\" %env.users[user_index].category)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Algorithm Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_optimizer = Greedy_optimizer(env)\n",
    "greedy_optimizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.optimal_reward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 : Uncertain Convertion Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from step3_learner import TS_learner3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a = np.ones((5,4))\n",
    "b = np.ones((5,4))\n",
    "initial_beta = [a, b]\n",
    "learner = TS_learner3(initial_beta, env, learning_rate = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 100\n",
    "daily_users = 200\n",
    "n_days = 200\n",
    "\n",
    "# delete possible old reward_history\n",
    "learner.reward_history = []\n",
    "learner.price_comb_history = []\n",
    "learner.cr_matrix_list = []\n",
    "\n",
    "for i in range(n_runs) :\n",
    "    learner.run(n_days, daily_users)\n",
    "\n",
    "opt_reward = learner.opt_reward\n",
    "collected_rewards = learner.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Salvo la history su file in modo che siamo sicuri ti riuscire a recuperarla anche in un secondo momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_rewards', 'wb') as f: \n",
    "    pickle.dump(collected_rewards, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Per recuperare, invece, i risultati ottenuti in un secondo momento :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_rewards', 'rb') as f: \n",
    "    collected_rewards = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward - collected_rewards, axis=0)), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward - collected_rewards, axis=0), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "#plt.plot(np.std(opt - gr_rewards_per_experiment, axis=0), 'g')  #'g' stay for green, the color for the Greedy algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_R = np.mean(R, axis=0)\n",
    "cum_R = np.cumsum(opt_reward - collected_rewards, axis = 1)\n",
    "mean_cum_R = np.mean(cum_R, axis = 0)\n",
    "std_dev = np.std(cum_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R)\n",
    "plt.fill_between(range(n_days), mean_cum_R-std_dev, mean_cum_R+std_dev, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the istant regret in the collected runs of the step 3 learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_reward = learner.opt_reward\n",
    "(opt_reward - collected_rewards)[-2][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODICE PER TESTARE SE UN PREZZO PER UN DETERMINATO PRODOTTO E' STATO \"ESPLORATO\" DALL'ALGORITMO\n",
    "comb_list = learner.price_comb_history[-1]\n",
    "count = 0\n",
    "prod = 0\n",
    "price = 0\n",
    "\n",
    "for comb in comb_list :\n",
    "    count += 1 if comb[prod] == price else 0\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.price_comb_history[-1][-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between mean conversion rates estimated by last run of TS and real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_mean = np.array(learner.cr_matrix_list).mean(axis = 0)\n",
    "i = 90\n",
    "CR_i = learner.cr_matrix_list[i]\n",
    "print(\"Mean of estimated conversion rates \\n\", CR_mean)\n",
    "print(\"\\nEstimated conversion rates for run %d \\n\" %i, CR_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matrix(env.theoretical_values['conversion_rates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.optimal_reward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### ucb1 (with greedy optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb1_greedy_R = []\n",
    "ucb1g_collected_rewards = []\n",
    "for _ in range(n_runs):\n",
    "    ucb_greedy = ucb1_greedy(len(prices), len(prices[0]), prices, env)\n",
    "    instant_regret = []\n",
    "    ucb1g_collected_rewards_temp = []\n",
    "    for t in range(n_days):\n",
    "        pulled_arms = ucb_greedy.pull_arms()\n",
    "        estimated_CR = env.simulate_day(daily_users, pulled_arms, [\"conversion_rates\"])['CR_vector']\n",
    "        ucb_greedy.update(pulled_arms, estimated_CR)\n",
    "        reward = env.expected_reward(pulled_arms)\n",
    "        ucb1g_collected_rewards_temp.append(reward)\n",
    "        instant_regret.append(opt_reward - reward)\n",
    "    ucb1g_collected_rewards.append(ucb1g_collected_rewards_temp)\n",
    "    cumulative_regret = np.cumsum(instant_regret)\n",
    "    ucb1_greedy_R.append(cumulative_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"ucb1_greedy_R\", 'wb') as f1:\n",
    "    pickle.dump(ucb1_greedy_R, f1)\n",
    "with open(\"ucb1g_collected_rewards\", 'wb') as f1:\n",
    "    pickle.dump(ucb1g_collected_rewards, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"ucb1_greedy_R\", 'rb') as f1:\n",
    "    ucb1_greedy_R = pickle.load(f1)\n",
    "with open(\"ucb1g_collected_rewards\", 'rb') as f1:\n",
    "    ucb1g_collected_rewards = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the result\n",
    "mean_ucbg_R = np.mean(ucb1_greedy_R, axis=0)\n",
    "std_dev_ucbg = np.std(ucb1_greedy_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_ucbg_R)\n",
    "plt.fill_between(range(n_days), mean_ucbg_R-std_dev_ucbg, mean_ucbg_R+std_dev_ucbg, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(ucb1g_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### ucb1 (brute force approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 2\n",
    "\n",
    "ucb1_bforce_R = []\n",
    "ucb1bf_collected_rewards = []\n",
    "for _ in range(n_runs):\n",
    "    ucb_brute_force = ucb1_brute_force(len(prices), len(prices[0]), prices, env)\n",
    "    instant_regret = []\n",
    "    ucb1bf_collected_rewards_temp = []\n",
    "    for t in range(n_days):\n",
    "        pulled_arms = ucb_brute_force.pull_arms()\n",
    "        estimated_CR = env.simulate_day(daily_users, pulled_arms, [\"conversion_rates\"])['CR_vector']\n",
    "        ucb_brute_force.update(pulled_arms, estimated_CR)\n",
    "        reward = env.expected_reward(pulled_arms)\n",
    "        ucb1bf_collected_rewards_temp.append(reward)\n",
    "        instant_regret.append(opt_reward - reward)\n",
    "    ucb1bf_collected_rewards.append(ucb1bf_collected_rewards_temp)\n",
    "    cumulative_regret = np.cumsum(instant_regret)\n",
    "    ucb1_bforce_R.append(cumulative_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"ucb1_bforce_R\", 'wb') as f1:\n",
    "    pickle.dump(ucb1_bforce_R, f1)\n",
    "with open(\"ucb1bf_collected_rewards\", 'wb') as f1:\n",
    "    pickle.dump(ucb1bf_collected_rewards, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"ucb1_bforce_R\", 'rb') as f1:\n",
    "    ucb1_bforce_R = pickle.load(f1)\n",
    "with open(\"ucb1bf_collected_rewards\", 'rb') as f1:\n",
    "    ucb1bf_collected_rewards = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the result\n",
    "mean_ucbbf_R = np.mean(ucb1_bforce_R, axis=0)\n",
    "std_dev_ucbbf = np.std(ucb1_bforce_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_ucbbf_R)\n",
    "plt.fill_between(range(n_days), mean_ucbbf_R-std_dev_ucbbf, mean_ucbbf_R+std_dev_ucbbf, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(ucb1bf_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save_data = []\n",
    "d = 5\n",
    "for i in range(3):\n",
    "    to_save_dict = {}\n",
    "    to_save_dict[\"CR_vector\"] = np.ones((2, d))\n",
    "    to_save_data.append(copy.deepcopy(to_save_dict))\n",
    "final_dict = {}\n",
    "final_dict[\"CR_vector\"] = np.sum([tsd[\"CR_vector\"] for tsd in to_save_data], axis = 0)\n",
    "final_dict[\"CR_vector\"]                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
