{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Environment import *\n",
    "from UserCat import UserCat\n",
    "from Product import Product\n",
    "from Greedy_optimizer import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from step3_ucb1 import *\n",
    "from step4_ucb1 import *\n",
    "from step5_ucb1 import *\n",
    "from Step3_TS import *\n",
    "from Step4_TS import *\n",
    "from Step5_TS import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT DEFINITION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Environment fixed informations and Products definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "products=[]\n",
    "\n",
    "nameofproduct= [ #name of products\n",
    "    \"Calabazas\",\n",
    "    \"Hinojo\",\n",
    "    \"Sesamo\",\n",
    "    \"Girasol\",\n",
    "    \"Amapola\"\n",
    "]\n",
    "# Dictionary fixing the secondary products linked to \n",
    "secondary_dict= {        \n",
    "    \"Calabazas\": [1,2],\n",
    "    \"Hinojo\": [0,2],\n",
    "    \"Sesamo\": [1,3],\n",
    "    \"Girasol\": [2,4],\n",
    "    \"Amapola\": [2,3]\n",
    "}\n",
    "\n",
    "# Matrix n_prod*n_prices collecting the possible prices for each product. Prices are in ascending order\n",
    "prices = [[8., 9, 10, 11],\n",
    "          [10., 11, 12, 13],\n",
    "          [20., 21, 23, 25],\n",
    "          [28., 30, 31, 33],\n",
    "          [40., 42, 43, 45]]\n",
    "# Production cost of the products\n",
    "cost = [5, 7.8, 18.1, 23.5, 32]\n",
    "\n",
    "#sarebbe interessante anche prendere da file il tutto così da cambiare tutto più facilmente\n",
    "#calcolo i margini dai cost mi sembra più sensato e anche più veloce se dobbiamo cambiare continuamente\n",
    "# Computation of margins linked to each product for a particular choice of price\n",
    "cost2 = np.tile(np.array([cost]).transpose(), (1, 4))\n",
    "margins = np.array(prices)-cost2\n",
    "# Creation of the 5 objects of Product class\n",
    "for i in range (5):\n",
    "    products.append(Product(prices[i], i, nameofproduct[i],margins[i]))\n",
    "\n",
    "# Parameter for the computation of the click probability on the SECOND secondary product\n",
    "lambda_q = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 1: Young and Inexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_1 = {\n",
    "    \"mean\": [9, 15, 22, 33, 35],\n",
    "    \"std\": [1, 2, 1, 1.5, 1.5]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_1 = [[0, 0.7, 0.3, 0, 0],\n",
    "                 [0.6, 0, 0.5, 0, 0],\n",
    "                 [0, 0.7, 0, 0.3, 0],\n",
    "                 [0, 0, 0.4, 0, 0.1],\n",
    "                 [0.5, 0, 0.3, 0, 0]]\n",
    "prob_lambda_1 = lambda_correct(np.matrix(probabilities_1), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_1 = [15, 15, 10, 5, 5]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_1 = [2, 1, .5, .2, .1]\n",
    "\n",
    "user1 = UserCat(alphas_1, res_price_params_1, poisson_lambda_1, prob_lambda_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 2: Old and Inexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_2 = {\n",
    "    \"mean\": [9, 16, 25, 41, 47],\n",
    "    \"std\": [1, 2.5, 1.5, 3, 2]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_2 = [[0, 0.5, 0.4, 0, 0],\n",
    "                 [0.4, 0, 0.6, 0, 0],\n",
    "                 [0, 0.7, 0, 0.5, 0],\n",
    "                 [0, 0, 0.5, 0, 0.3],\n",
    "                 [0, 0, 0.5, 0.3, 0]]\n",
    "prob_lambda_2 = lambda_correct(np.matrix(probabilities_2), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_2 = [7, 12, 12, 12, 7]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_2 = [0.5, 1, 2, 1, 0.5]\n",
    "\n",
    "user2 = UserCat(alphas_2, res_price_params_2, poisson_lambda_2, prob_lambda_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 3: Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_3 = {\n",
    "    \"mean\": [8, 13, 24, 39, 50],\n",
    "    \"std\": [1, 1.5, 2, 2, 1.5]\n",
    "}\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_3 = [[0, 0, 0.6, 0.4, 0],\n",
    "                 [0, 0, 0, 0.7, 0.4],\n",
    "                 [0, 0.4, 0, 0.6, 0],\n",
    "                 [0, 0, 0.3, 0, 0.7],\n",
    "                 [0, 0, 0.4, 0.6, 0]]\n",
    "prob_lambda_3 = lambda_correct(np.matrix(probabilities_2), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_3 = [5, 5, 10, 15, 15]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_3 = [0.1, 0.2, 0.5, 1.5, 1.5]\n",
    "\n",
    "user3 = UserCat(alphas_3, res_price_params_3, poisson_lambda_3, prob_lambda_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Category 0: Aggregated demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the distribution describing the reservation price\n",
    "res_price_params_0 = {\n",
    "    \"mean\": [9.7, 12.7, 24.5, 31.6, 41.1],\n",
    "    \"std\": [1.5, 2, 4, 2.5, 3]\n",
    "}\n",
    "\n",
    "# Matrix collecting the graph_weights describing mechanism of click on secondary products\n",
    "probabilities_0 = [[0, 0.6, 0.2, 0, 0],\n",
    "                 [0.5, 0, 0.4, 0, 0],\n",
    "                 [0, 0.5, 0, 0.5, 0],\n",
    "                 [0, 0, 0.6, 0, 0.5],\n",
    "                 [0, 0, 0.3, 0.5, 0]]\n",
    "prob_lambda_0 = lambda_correct(np.matrix(probabilities_0), secondary_dict, lambda_q)\n",
    "# Parameter of the Dirichlet for the alphas ratio sampling\n",
    "alphas_0 = [10, 10, 10, 10, 10]\n",
    "# Parameter of the Poisson distribution determining the number of product bought\n",
    "# ! we considered a trasleted Poisson in 1, to avoid the case of 0 items bought, so\n",
    "#   the mean is poisson_lambda+1\n",
    "poisson_lambda_0 = [1.5, 1, .5, .5, .2]\n",
    "\n",
    "user0 = UserCat(alphas_0, res_price_params_0, poisson_lambda_0, prob_lambda_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Environment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE WITH 3 USERS :\n",
    "# list of users \n",
    "users3 = [user1, user2, user3]\n",
    "feature_matrix3 = np.array([[0, 1], [2, 2]])\n",
    "# probability distribution of the feature\n",
    "feature_prob = [0.3, 0.4]\n",
    "env3 = Environment(users3, products, secondary_dict, feature_matrix3, feature_prob)\n",
    "\n",
    "# CASE WITH AGGREGATED USER :\n",
    "users0 = [user0]\n",
    "feature_matrix0 = np.array([[0, 0], [0, 0]])\n",
    "env = Environment(users0, products, secondary_dict, feature_matrix0, feature_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.optimal_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.expected_reward([2,3,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matrix(env.theoretical_values['conversion_rates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "d = env3.simulate_day_context(200, [[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]], np.array([[0,1],[2,2]]), \n",
    "[\"conversion_rates\", \"alpha_ratios\", \"products_sold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "a = env3.simulate_day(2000, [0,0,0,0,0], [\"conversion_rates\", \"alpha_ratios\", \"products_sold\", \"graph_weights\"], aggregated= False)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reservation Price Distribution Plot for one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = 0\n",
    "x = np.arange(0, 60 , .01)\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "color_list = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "for i in range(5):\n",
    "    res_price_distr = env.users[user_index].res_price_distr[i]\n",
    "    y = res_price_distr.pdf(x)\n",
    "    plt.plot(x, y, label = 'Product %d' %i, color = color_list[i])\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        plt.scatter(prices[i][j], 0.025, color = color_list[i])\n",
    "\n",
    "plt.title(\"Reservation Price Distributions for the user category %s\" %env.users[user_index].category)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of Prouducts Sold Distributions Plot for a User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = 0\n",
    "x = np.arange(0, 10, 1)\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "color_list = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "for i in range(5):\n",
    "    pois_l = env.users[user_index].poisson_lambda[i]\n",
    "    distr = scipy.stats.poisson(pois_l)\n",
    "    y = distr.pmf(x[:-1])\n",
    "    y = np.insert(y, 0, 0)\n",
    "    plt.plot(x, y, label = 'Product %d' %i, color = color_list[i])\n",
    "    #plt.scatter(x, y, color = color_list[i], label = 'Product %d' %i)\n",
    "    #plt.vlines(x, 0, y, color = color_list[i], lw=5, alpha=0.5)\n",
    "\n",
    "plt.title(\"Number of Prouducts Sold Distributions for the user category %s\" %env.users[user_index].category)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Algorithm Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_optimizer = Greedy_optimizer(env)\n",
    "greedy_optimizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.optimal_reward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 : Uncertain Convertion Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a = np.ones((5,4))\n",
    "b = np.ones((5,4))\n",
    "initial_beta = [a, b]\n",
    "learner = Step3_TS(env, initial_beta, learning_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for the algorithm execution\n",
    "n_runs = 200\n",
    "daily_users = 200\n",
    "n_days = 300\n",
    "\n",
    "# delete possible old informations form past runs \n",
    "learner.reward_history = []\n",
    "learner.price_comb_history = []\n",
    "learner.cr_matrix_list = []\n",
    "\n",
    "# execute the algorithm n_runs times\n",
    "for i in range(n_runs) :\n",
    "    learner.run(n_days, daily_users)\n",
    "\n",
    "# collect all informations for the plot\n",
    "opt_reward = learner.opt_reward\n",
    "collected_rewards = learner.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Salvo la history su file in modo che siamo sicuri ti riuscire a recuperarla anche in un secondo momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_rewards', 'wb') as f: \n",
    "    pickle.dump(collected_rewards, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Per recuperare, invece, i risultati ottenuti in un secondo momento :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_rewards', 'rb') as f: \n",
    "    collected_rewards = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward - collected_rewards, axis=0)), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward - collected_rewards, axis=0), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "#plt.plot(np.std(opt - gr_rewards_per_experiment, axis=0), 'g')  #'g' stay for green, the color for the Greedy algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_R = np.mean(R, axis=0)\n",
    "cum_R = np.cumsum(opt_reward - collected_rewards, axis = 1)\n",
    "mean_cum_R = np.mean(cum_R, axis = 0)\n",
    "std_dev = np.std(cum_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R)\n",
    "plt.fill_between(range(n_days), mean_cum_R-std_dev, mean_cum_R+std_dev, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the istant regret in the collected runs of the step 3 learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_reward = learner.opt_reward\n",
    "(opt_reward - collected_rewards)[-2][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.price_comb_history[-1][-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Comparison between mean conversion rates estimated by last run of TS and real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_mean = np.array(learner.cr_matrix_list).mean(axis = 0)\n",
    "i = 9\n",
    "CR_i = learner.cr_matrix_list[i]\n",
    "print(\"Mean of estimated conversion rates \\n\", CR_mean)\n",
    "\n",
    "print(\"\\nEstimated conversion rates for run %d \\n\" %i, CR_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matrix(env.theoretical_values['conversion_rates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODICE PER TESTARE SE UN PREZZO PER UN DETERMINATO PRODOTTO E' STATO \"ESPLORATO\" DALL'ALGORITMO\n",
    "comb_list = learner.price_comb_history[-1]\n",
    "count = 0\n",
    "prod = 0\n",
    "price = 0\n",
    "\n",
    "for comb in comb_list :\n",
    "    count += 1 if comb[prod] == price else 0\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the run parameters\n",
    "n_runs = 2\n",
    "daily_users = 200\n",
    "n_days = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_reward = env.optimal_reward()[0]\n",
    "ucb3 = step3_ucb1(len(prices), len(prices[0]), prices, env)\n",
    "for _ in range(n_runs):\n",
    "    ucb3.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"ucb3\", 'wb') as f1:\n",
    "    pickle.dump(ucb3, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"ucb3\", 'rb') as f1:\n",
    "    ucb3 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_ucb1_collected_rewards = ucb3.collected_rewards\n",
    "step3_ucb1_R = ucb3.regret\n",
    "# plot of the result\n",
    "mean_step3_ucb1_R = np.mean(step3_ucb1_R, axis=0)\n",
    "std_dev_step3_ucb1 = np.std(step3_ucb1_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_step3_ucb1_R)\n",
    "plt.fill_between(range(n_days), mean_step3_ucb1_R-std_dev_step3_ucb1, mean_step3_ucb1_R+std_dev_step3_ucb1, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(step3_ucb1_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last n pulled arms\n",
    "print(\"Last n pulled arms:\")\n",
    "np.array(ucb3.pulled[-10:-1], dtype=np.int32)[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ucb1 most pulled arms\n",
    "combinations_data = [[] for i in range(1024)]\n",
    "for i1 in range(4):\n",
    "    for i2 in range(4):\n",
    "        for i3 in range(4):\n",
    "            for i4 in range(4):\n",
    "                for i5 in range(4):\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append([i1, i2, i3, i4, i5])\n",
    "                    c = np.array(np.array(ucb3.pulled, dtype=np.int32)[:, 0].tolist()) == [i1, i2, i3, i4, i5]\n",
    "                    c = np.prod(c, axis=1)\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(np.count_nonzero(c))\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(env.expected_reward([i1, i2, i3, i4, i5]))\n",
    "                    x = combinations_data\n",
    "result = []\n",
    "for i in range(20):\n",
    "    result.append(x[np.argmax(np.array(x)[:, 1])])\n",
    "    x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n",
    "print(\"Optimal arms combination:\")\n",
    "print(env.optimal_reward()[1], env.optimal_reward()[0])\n",
    "print(\"\\n\\nUcb1 most pulled arms:\")\n",
    "print(\"(arms combination), (n° pulls), (exp rew)\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb3.print_estimations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 : Uncertain conversion rates, alpha ratio and number of products sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a = np.ones((5,4))\n",
    "b = np.ones((5,4))\n",
    "initial_beta_CR = [a, b]\n",
    "initial_beta_alpha = np.ones((2,5))\n",
    "initial_n_prod_data = np.ones((2,5))\n",
    "learner = Step4_TS(env, initial_beta_CR, initial_beta_alpha, initial_n_prod_data, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for the algorithm execution\n",
    "n_runs = 2\n",
    "daily_users = 200\n",
    "n_days = 300\n",
    "\n",
    "# delete possible old informations form past runs \n",
    "learner.reward_history = []\n",
    "learner.price_comb_history = []\n",
    "learner.cr_matrix_list = []\n",
    "learner.alpha_ratios_list = []\n",
    "learner.n_prod_list = []\n",
    "\n",
    "# execute the algorithm n_runs times\n",
    "for i in range(n_runs) :\n",
    "    learner.run(n_days, daily_users)\n",
    "\n",
    "# collect all informations for the plot\n",
    "opt_reward = learner.opt_reward\n",
    "collected_rewards = learner.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward - collected_rewards, axis=0)), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward - collected_rewards, axis=0), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "#plt.plot(np.std(opt - gr_rewards_per_experiment, axis=0), 'g')  #'g' stay for green, the color for the Greedy algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_R = np.mean(R, axis=0)\n",
    "cum_R = np.cumsum(opt_reward - collected_rewards, axis = 1)\n",
    "mean_cum_R = np.mean(cum_R, axis = 0)\n",
    "std_dev = np.std(cum_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R)\n",
    "plt.fill_between(range(n_days), mean_cum_R-std_dev, mean_cum_R+std_dev, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the run parameters\n",
    "n_runs = 2\n",
    "daily_users = 200\n",
    "n_days = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_reward = env.optimal_reward()[0]\n",
    "ucb4 = step4_ucb1(len(prices), len(prices[0]), prices, env)\n",
    "for _ in range(n_runs):\n",
    "    ucb4.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"ucb4\", 'wb') as f1:\n",
    "    pickle.dump(ucb4, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"ucb4\", 'rb') as f1:\n",
    "    ucb4 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_ucb1_collected_rewards = ucb4.collected_rewards\n",
    "step4_ucb1_R = ucb4.regret\n",
    "# plot of the result\n",
    "mean_step4_ucb1_R = np.mean(step4_ucb1_R, axis=0)\n",
    "std_dev_step4_ucb1 = np.std(step4_ucb1_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_step4_ucb1_R)\n",
    "plt.fill_between(range(n_days), mean_step4_ucb1_R-std_dev_step4_ucb1, mean_step4_ucb1_R+std_dev_step4_ucb1, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(step4_ucb1_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last n pulled arms\n",
    "print(\"Last n pulled arms:\")\n",
    "np.array(ucb4.pulled[-10:-1], dtype=np.int32)[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ucb1 most pulled arms\n",
    "combinations_data = [[] for i in range(1024)]\n",
    "for i1 in range(4):\n",
    "    for i2 in range(4):\n",
    "        for i3 in range(4):\n",
    "            for i4 in range(4):\n",
    "                for i5 in range(4):\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append([i1, i2, i3, i4, i5])\n",
    "                    c = np.array(np.array(ucb4.pulled, dtype=np.int32)[:, 0].tolist()) == [i1, i2, i3, i4, i5]\n",
    "                    c = np.prod(c, axis=1)\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(np.count_nonzero(c))\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(env.expected_reward([i1, i2, i3, i4, i5]))\n",
    "                    x = combinations_data\n",
    "result = []\n",
    "for i in range(20):\n",
    "    result.append(x[np.argmax(np.array(x)[:, 1])])\n",
    "    x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n",
    "print(\"Optimal arms combination:\")\n",
    "print(env.optimal_reward()[1], env.optimal_reward()[0])\n",
    "print(\"\\n\\nUcb1 most pulled arms:\")\n",
    "print(\"(arms combination), (n° pulls), (exp rew)\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb4.alphas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb4.print_estimations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 : Uncertain conversion rates and graph weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial assumptions for beta parameters (uniform distr. on [0, 1])\n",
    "a_cr = np.ones((5,4))\n",
    "b_cr = np.ones((5,4))\n",
    "initial_beta_CR = [a_cr, b_cr]\n",
    "a_gw = np.ones((5,2))\n",
    "b_gw = np.ones((5,2))\n",
    "initial_beta_gw = [a_gw, b_gw]\n",
    "learner = Step5_TS(env, initial_beta_CR, initial_beta_gw, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for the algorithm execution\n",
    "n_runs = 200\n",
    "daily_users = 200\n",
    "n_days = 300\n",
    "\n",
    "# delete possible old informations form past runs \n",
    "learner.reward_history = []\n",
    "learner.price_comb_history = []\n",
    "learner.cr_matrix_list = []\n",
    "learner.graph_weights_list = []\n",
    "\n",
    "# execute the algorithm n_runs times\n",
    "for i in range(n_runs) :\n",
    "    learner.run(n_days, daily_users)\n",
    "\n",
    "# collect all informations for the plot\n",
    "opt_reward = learner.opt_reward\n",
    "collected_rewards = learner.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Cumulative Regret Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.title(\"Cumulative Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt_reward - collected_rewards, axis=0)), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Standard Deviation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.title(\"Regret's Standard Deviation\")\n",
    "plt.plot(np.std(opt_reward - collected_rewards, axis=0), 'r')  #'r' stay for red, the color for the TS algorithm\n",
    "#plt.plot(np.std(opt - gr_rewards_per_experiment, axis=0), 'g')  #'g' stay for green, the color for the Greedy algorithm\n",
    "plt.legend([\"TS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_R = np.mean(R, axis=0)\n",
    "cum_R = np.cumsum(opt_reward - collected_rewards, axis = 1)\n",
    "mean_cum_R = np.mean(cum_R, axis = 0)\n",
    "std_dev = np.std(cum_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_cum_R)\n",
    "plt.fill_between(range(n_days), mean_cum_R-std_dev, mean_cum_R+std_dev, alpha=0.4)\n",
    "plt.title(\"Cumulative Regret and its Std. Deviation\")\n",
    "plt.xlabel(\"t (days)\")\n",
    "plt.ylabel(\"Cum_Regret(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Comparison between Optimal and Expected Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.title(\"Optimal VS Expected Reward\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Expected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the run parameters\n",
    "n_runs = 2\n",
    "daily_users = 200\n",
    "n_days = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_reward = env.optimal_reward()[0]\n",
    "ucb5 = step5_ucb1(len(prices), len(prices[0]), prices, env)\n",
    "for _ in range(n_runs):\n",
    "    ucb5.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result\n",
    "with open(\"ucb5\", 'wb') as f1:\n",
    "    pickle.dump(ucb5, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result\n",
    "with open(\"ucb5\", 'rb') as f1:\n",
    "    ucb5 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step5_ucb1_collected_rewards = ucb5.collected_rewards\n",
    "step5_ucb1_R = ucb5.regret\n",
    "# plot of the result\n",
    "mean_step5_ucb1_R = np.mean(step5_ucb1_R, axis=0)\n",
    "std_dev_step5_ucb1 = np.std(step5_ucb1_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_step5_ucb1_R)\n",
    "plt.fill_between(range(n_days), mean_step5_ucb1_R-std_dev_step5_ucb1, mean_step5_ucb1_R+std_dev_step5_ucb1, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.axhline(opt_reward, color = 'green')\n",
    "plt.plot(np.mean(step5_ucb1_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last n pulled arms\n",
    "print(\"Last n pulled arms:\")\n",
    "np.array(ucb5.pulled[-10:-1], dtype=np.int32)[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ucb1 most pulled arms\n",
    "combinations_data = [[] for i in range(1024)]\n",
    "for i1 in range(4):\n",
    "    for i2 in range(4):\n",
    "        for i3 in range(4):\n",
    "            for i4 in range(4):\n",
    "                for i5 in range(4):\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append([i1, i2, i3, i4, i5])\n",
    "                    c = np.array(np.array(ucb5.pulled, dtype=np.int32)[:, 0].tolist()) == [i1, i2, i3, i4, i5]\n",
    "                    c = np.prod(c, axis=1)\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(np.count_nonzero(c))\n",
    "                    combinations_data[i1*(4**4) + i2*(4**3) + i3*(4**2) + i4*(4**1) + i5*(4**0)].append(env.expected_reward([i1, i2, i3, i4, i5]))\n",
    "                    x = combinations_data\n",
    "result = []\n",
    "for i in range(20):\n",
    "    result.append(x[np.argmax(np.array(x)[:, 1])])\n",
    "    x = np.delete(x, np.argmax(np.array(x)[:, 1]), axis=0).tolist()\n",
    "print(\"Optimal arms combination:\")\n",
    "print(env.optimal_reward()[1], env.optimal_reward()[0])\n",
    "print(\"\\n\\nUcb1 most pulled arms:\")\n",
    "print(\"(arms combination), (n° pulls), (exp rew)\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb5.print_estimations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: Context generation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 7 --> daily users\n",
    "feature_list = [[[0,1]], [[0,0],[1,0]], [[1,1]]]\n",
    "learner_list = []\n",
    "sampled_value_list = []\n",
    "simul_info ->dict{'00' : dict( CR_matrix qui! )} # informazioni delle simulazioni dal giorno 0 al giorno t\n",
    "\n",
    "# sample per ogni learner delle quantità incerte\n",
    "for learner in learner_list :\n",
    "    sampled_value_list[i]['CR'] =learner.sample_CR\n",
    "    ..\n",
    "\n",
    "# greedy optimizer per ogni context generato\n",
    "for learner in learner_list :\n",
    "    opt_price_comb[i] = greedy_optimizer(...)\n",
    "\n",
    "# simulazione della giornata\n",
    "daily_informations = simulate_day(daily_users, opr_price_comb_list, uncertain_list, context = feature_list)\n",
    "->dict{'00' : dict(output simulate_day classico + count delle volte che la coppia di feature è uscita)}\n",
    "\n",
    "# ! aggiornamento informazioni simulazione\n",
    "simul_info.update(daily_informations, opt_price_comb_list) # update NON E' un append ma sommi i valori corrispondenti\n",
    "\n",
    "# aggiornamento dei parametri:\n",
    "for learner in learner_list :\n",
    "    ... # rielaborazione di daily_information basa su feature_list (quindi aggreghi per context; aggregare = somma)\n",
    "    learner.update_parameters(opt_price_combI, ...)\n",
    "\n",
    "###### CONTEXT GENERATION ######\n",
    "... > output: feature_list ...\n",
    "# --> ridefinire learner_list in base al nuovo feature_list\n",
    "# i parametri per beta o medie li prendiamo da simul info --> per le beta possiamo definire un \"variability_rate\" tra 0 e 1 \n",
    "# per rimpicciolire i valori da mettere per A e B della beta (A e B matrici 5x4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simul_dict = {'00':{'alpha', 'CR', 'prod'}}\n",
    "expected_reward(price_comb, uncertain, feature_list = [[0,1], [0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.beta_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser matrice --> feature_list\n",
    "n_groups = np.max(matrix)+1\n",
    "feature_list = []\n",
    "for i in len(n_groups):\n",
    "    ind_list = return_indices(matrix, i)\n",
    "    feature_list.append(list(feature_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ABRUBT CHANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abrupt_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 20\n",
    "daily_users = 200\n",
    "n_days = 300\n",
    "\n",
    "#########################\n",
    "# ABRUPT CHANGE SETTING #\n",
    "#########################\n",
    "changes_dict ={      \n",
    "    50 : {\"mean\": [9.0, 11.3, 23.2, 30.1, 39.7], \"std\": [1.3, 1.7, 3.5, 2.1, 2.7]},\n",
    "    120 : {\"mean\": [10.5, 14.0, 25.8, 32.0, 43.0], \"std\": [1.7, 2.2, 4.3, 2.9, 3.2]},\n",
    "    200 : {\"mean\": [9.7, 12.7, 24.5, 31.6, 41.1], \"std\": [1.5, 2, 4, 2.5, 3]}\n",
    "}\n",
    "opt_reward = env.optimal_reward()[0]\n",
    "opt_reward_evolution = np.zeros(n_days)\n",
    "original_res_price_param = copy.deepcopy(env.users[0].res_price_params)\n",
    "for t in range(n_days):\n",
    "    if t in changes_dict.keys(): \n",
    "        env.abrupt_change_deterministic([changes_dict[t]])\n",
    "        opt_reward = env.optimal_reward()[0]\n",
    "    opt_reward_evolution[t] = opt_reward\n",
    "\n",
    "env.abrupt_change_deterministic([original_res_price_param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb_changes = Abrupt_learner(len(prices), len(prices[0]), prices, env, changes_dict)\n",
    "for _ in range(n_runs):\n",
    "    ucb_changes.run(n_days, daily_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "changes_collected_rewards = ucb_changes.collected_rewards\n",
    "changes_R = ucb_changes.regret\n",
    "# plot of the result\n",
    "mean_changes_R = np.mean(changes_R, axis=0)\n",
    "std_changes = np.std(changes_R, axis=0)/np.sqrt(n_runs)\n",
    "plt.plot(mean_changes_R)\n",
    "plt.fill_between(range(n_days), mean_changes_R-std_changes, mean_changes_R+std_changes, alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABBMUlEQVR4nO3dd5hU5dn48e89s40tsOwCK30pK0UpKopIsSKK3Zgo0QiJxhI1aizRmESM5c37atRYoiGxoQYbYvnFhghihwWX3vsuZZftjS0zz++Pc2YYYAZmdhem3Z/r2mtnTn3OOXPueeY+z3mOGGNQSikVuxzhLoBSSqnDSwO9UkrFOA30SikV4zTQK6VUjNNAr5RSMU4DvVJKxTgN9OqIEZEpIvJ1uMvhS0R6iUiNiDgPw7Knishrbb3ctiIip4lIoc/7zSJyViSVSbUNDfQxwj5J6+2gtVNEXhaR9HCXq63ZXxbLRKTO3s7nRCQzhPn3CWbGmK3GmHRjjOuwFPgIEJGfi0i+fex3iMjHIjImTGV5WUQeCse6VWAa6GPLBcaYdGA4cBxwb7gKIiIJh2GZdwD/C9wFdABOBnoDs0Ukqa3XFw1E5HfAk8AjQA7QC/gHcFEYi6UijAb6GGSM2Ql8ihXwARCRk0XkWxGpEJElInKaPfx0EVnmM91sEVno8/4rEbnYfn2PiGwQkWoRWSkil/hMN0VEvhGRJ0SkFJgqItki8oGIVInIAqBfS7dJRNoDDwC3GGM+McY0GWM2Az8DcoGr7Ommisg7IvKmXc7FIjLMHvcqViD80K793i0iuSJiPF9MIjJPRB6y91WNiHxob8fr9nYsFJFcn3L9XUS22eMWicjYILdnlYic7/M+QURKROR4EUkRkddEpNQ+XgtFJMfPMjoAfwFuMsa8a4yptffLh8aYu+xpkkXkSRHZbv89KSLJQZTP4XO8S0XkLRHJ8hk/xufztM0+/tcBVwJ3e/adPW03EZlpb98mEfmtz3La2b8CykVkJXBiMPtPhcgYo38x8AdsBs6yX/cAlgF/t993B0qBiVhf7uPt952BdsAeoBOQCOwCioAMe1w9kG0v56dAN3sZlwO1QFd73BSgGbgFSLDnfQN4C0gDjrWX+3ULt+8ce/kJfsa9AsywX08FmoDL7O25E9gEJO6/n+z3uYDxLBeYB6zH+lLqAKwE1gJn2ds1HXjJZ/6rgGx73B3ATiDFpyyvBdiePwOv+7w/D1hlv74e+BBIBZzACUD7UPaJzzR/Ab4HutjH+1vgQXvcaUBhgM/QrfZ8PYBk4J8++7g3UA1MsvdxNjDcHvcy8JDPMh3AInt7k4C+wEZggj3+r8BXQBbQE1juWyb9a5s/rdHHlvdEpBrYBhQD99vDrwI+MsZ8ZIxxG2NmA/nARGNMPbAQGIcVUJYA3wCjsVIj64wxpQDGmLeNMdvtZbwJrANO8ln/dmPM08aYZqAR+AnwZ2PVNJdjBeSW6gTstpe9vx32eI9Fxph3jDFNwONAir0twXrJGLPBGFMJfAxsMMZ8bq/7bay0GADGmNeMMaXGmGZjzN+wguKAINbxH+BCEUm13/8cmGG/bsIKnv2NMS5jzCJjTJWfZWQTeJ94XAn8xRhTbIwpwfpV9IsgyncDcJ8xptAY04D1pXWZ/cvn58DnxpgZxvoFUWqMKQiwnBOBzsaYvxhjGo0xG4F/AVfY438GPGyMKTPGbAOeCqJsKkQa6GPLxcaYDKya2kD2Br/ewE/tn9kVIlIBjAG62uO/tOcZZ7+eB5xq/33pWbiIXC0iBT7LOJZ9A+w2n9edsWq5vsO2BCq4iDxv/9yvEZE/+JlkN9ApQO6/qz3+gHIYY9xAIdYvkWDt8nld7+e99yK3iNxpp2Eq7X3SgX33iV/GmPXAKuACO9hfiBX8AV7FSr29Yadb/k9EEv0sppTA+8SjG/vu9y0Ety96A7N8jvUqwIV1HaAnsCGIZXiW022/z94f7OV4yhfUZ0S1nAb6GGSM+RLrJ/Rj9qBtwKvGmEyfvzRjzF/t8fsH+i/ZL9CLSG+smtjNWKmcTKyf2eK7ap/XJVhphZ4+w3odpMw3GKv1S7ox5hE/k3wHNACX+g4Uq2XRucAcn8E9fcY7sNIP2/2UsVXsfPzdWLXSjvY+qWTffXIwM7DSHxcBK+3gj11LfsAYMxg4BTgfuNrP/J59cvFB1rEdK9h69GLvvjiYbcC5+31mUowxRfa4QNdb9t+/24BN+y0nwxgz0R6/gyA/I6rlNNDHrieB8faFyNewao4TRMRpX+w7TUR62NN+i5VuOAlYYIxZgRUcRgLz7WnSsE7iEgAR+SVWjd4vYzVXfBfromyqiAwGJrd0Y+w0ygPA0yJyjogk2hdF38Kqsb/qM/kJInKpXdO9DSsYfm+P24WVJ24LGVhfZiVAgoj8GWgfwvxvAGcDN7K3Nu+5QD5ErLb9VVipHPf+M9v75M/AsyJysb2fE0XkXBH5P3uyGcAfRaSziHSypw+mbf/zwMP2Fzz2/J6WPK8DZ4nIz+yLyNkiMtwet//+XQBUi8jv7QuvThE5VkQ8F13fAu4VkY725/GWIMqmQqSBPkbZ+djpWDnybVi1xj9gBaVtWE0UHfa0tcBiYIUxptFexHfAFmNMsT3NSuBv9vBdwBCsXP7B3IyV5tiJ9QvjpVZu0//Z2/AYVgD8wd6WM+08ssf7WBeLy7Hy0Zfa+XqA/8EKfBUicmdryoOVXvkE62LtFqyL2tsOOocPY8wOrP15CvCmz6ijgHewtnEV1q+qVw9YgLWMvwG/A/7I3mN7M/CePclDWNdjlmJdoF9sDzuUvwMfAJ/Z132+x/rixxizFevC/h1AGVAADLPnewEYbO/f9+wv/POxWoBtwkqx/RsrxQXWl/cWe9xngbZTtY4Yow8eUbFDRKZiXcS8KtxlUSpSaI1eKaVinAZ6pZSKcZq6UUqpGKc1eqWUinFt3vFUW+jUqZPJzc0NdzGUUipqLFq0aLcxprO/cREZ6HNzc8nPzw93MZRSKmqISMC7ijV1o5RSMU4DvVJKxTgN9EopFeM00CulVIzTQK+UUjFOA71SSsU4DfRKKRXjIrIdvVIH88WmL5i3eV64ixHVjko/ihtH3IhIsM9IUdFMA72KOnfPvptFOxYhQT/ISfky9kOgLhxwIT3a9zjE1CoWaKBXUafJ3cTFAy9m1uWzwl2UqDR9yXQmvzeZRlfjoSdWMUFz9CrquI0bh+hHt6USHFb9rtndHOaSqCNFzxYVdTTQt44G+vijZ4uKOi63SwN9K3gCfZOr6RBTqlihZ4uKOlqjbx2t0ccfPVtU1NFA3zqJjkRAA308OeTZIiI9RWSuiKwUkRUicqs9fKqIFIlIgf03McD854jIGhFZLyL3tPUGqPijgb51tEYff4JpXtkM3GGMWSwiGcAiEZltj3vCGPNYoBlFxAk8C4wHCoGFIvKBMWZlawuu4pcG+tbRQB9/Dnm2GGN2GGMW26+rgVVA9yCXfxKw3hiz0RjTCLwBXNTSwioFGuhby3sx1q0XY+NFSGeLiOQCxwE/2INuFpGlIvKiiHT0M0t3YJvP+0ICfEmIyHUiki8i+SUlJaEUS8UZt3Hj0MtLLZbo1Bx9vAn6bBGRdGAmcJsxpgp4DugHDAd2AH9rTUGMMdOMMSOMMSM6d/b7fFulACvQOx3OcBcjamnqJv4EFehFJBEryL9ujHkXwBizyxjjMsa4gX9hpWn2VwT09Hnfwx6mVItp6qZ1NNDHn2Ba3QjwArDKGPO4z/CuPpNdAiz3M/tCIE9E+ohIEnAF8EHriqzinQb61tFAH3+CaXUzGvgFsExECuxhfwAmichwwACbgesBRKQb8G9jzERjTLOI3Ax8CjiBF40xK9p0C1TccRm9M7Y19M7Y+HPIQG+M+Rr89gf7UYDptwMTfd5/FGhapVpCa/StozdMxR89W1TU0UDfOpq6iT96tqioo4G+dTTQxx89W1TU0UDfOhro44+eLSrqaKBvHc8NU3pnbPzQs0VFHbdx4xS9YaqltEYffzTQq6ijNfrW0UAff/RsUVFHA33raKCPP8HcMKVUxDDGRHWg39Pkoqp+39x4p/RkHA6hyeUmwSE0uw1OEdzGUFbbeMAyOqYleadLcAgl1Q1+19W+XSIpiU5KaxpwuQ0AackJtEvSQB9vNNCrqGKwAlY0BvoNJTX87PnvKN0veE85JZffnN6Pnz7/Hd0z27Gzag+d0pKprG9iza7qA5ZzdE46XTJSKCyvo2dWKl+t2+13fR1TExmT15kPl2z3DktLcvLV78/AIQ69MzaOaKBXUcVt3KS4hlNSkRHuogSlpLqBG19bRGF5PVV7mmiX6OTBi47B4bBuNv90xS7eXLiNRVvK2VG5hy2ldSQnONi0u5ZEp4M/TBxIWvLe07S2oZlHP13D2l01JCc42Fxax02n96NbZrt91us28NScdXy4ZDs/G9GDYT0zKa1p5PHZa5m3ppgER4LW6OOIBnoVVdzGTU7jQ/y/7+GJC9wkOiOnZl9e28hf/t9Kdtc04HQIThE27q5lR2U9Fw7rhtPh4KqTe3FMtw7eeYb3zOS8p75m+fZK/nnVCThEyE5PoqK+ifTkBE7MzTpgPUfnZFBa00heTjrbK/ZwzrFH+S3PqL5ZfLehlCtH9sbhENxuw6vfb+H+91eQ5bqPhuaaw7YvVGTRQK+iitu4va+fmL2WoT06ICII4BDB4WDf9yKIQG6nNLrvV+sNRV1jMxuKa3n3x0KSEhzcMK4fHdOSvOOem7eB2St3sXF3LYO7tsdtDC63ISMlgT+edzxnDsrxu9xjunXgptP70bdTOmcf4z9g7++0AV28r4f2CDxd/y4Z9O+y95ePwyGM6d+JWT8WkcwJ1NR/HdT6VPTTQK+iitu4aZQtJJne/GPehqDna5fo5IZT+7FmVxV9O6Vz+/ijcToEY4x3mrLaRuasLuYnx/fA6djbj99/ftjKn95fjsttSE5w0Ow2LNpczmvXjiTR6eC3M35kzupiunVox9OTjmNCkAHb464JA0OavjWuP7Uvs360HgnR6HIdsfWq8NJAr6KKVaMXenWuYdqV52IMuI3BGLyv3ca6ZGvs4Y3Nbu6dtYwnPl9L98x2fLRsJ5tLa6lvdDFndTEAR7VPoWdWOxZuLufb9bsZ1S+b1Turee/HIsrrmhjTvxPnDe3KxCFd+Xrdbm76z2Juf7OAzNREPl9VzF8uOoarR+WGc9cEZeBR7fnHlcfzm9cX0+Qyh55BxQQN9CqquI0bQUhOcjPwqPZBz/f29aNYX1zDqH7Z/PXj1fxz/kbapyRw7Zg+pCUn8PoPW1i4uZyhPTrwXsF23ivYjkNg4pCuHJ2Twa/H9qVdknU37nlDu1JUMZBHPloNwK/H9omKIO/hua7R5HIfYkoVKzTQq6hi1eidOMTfIxIC69I+hS7tUwC4d+Igbh9/NIlOhzdFM+GYo/ho2Q5uPSuPirommlxuUpOcZKYm+V3edeP6MTavM80uw7Hdg//CiQSJTmubtUYfPzTQq6jiSd04QovzB0hJ3LevnMHd2jO4mxWwO2ckB7WMQV2jK8B7JNk1+mYN9HEjctqmKRUEl9uFYLWkUS2TmGCnbtwa6OOFBnoVVawavSPk1I3aK1Fr9HFHA72KKm7jBuNodeomnnly9Bro44cGehVV9uboNdK3lDdHr41u4sYhA72I9BSRuSKyUkRWiMit9vBHRWS1iCwVkVkikhlg/s0iskxECkQkv43Lr+KM1bxSa/StkaiBPu4EU6NvBu4wxgwGTgZuEpHBwGzgWGPMUGAtcO9BlnG6MWa4MWZEq0us4prW6FvPczG2WW+MjRuHDPTGmB3GmMX262pgFdDdGPOZMcbT/d33wEF63VCqbXgvxmqVvsU8OXq9Xyp+hJSjF5Fc4Djgh/1G/Qr4OMBsBvhMRBaJyHUHWfZ1IpIvIvklJSWhFEvFEW1103qeHL0G+vgRdKAXkXRgJnCbMabKZ/h9WOmd1wPMOsYYczxwLlbaZ5y/iYwx04wxI4wxIzp37hz0Bqj44ukCQSv0LefJ0bvduhPjRVCBXkQSsYL868aYd32GTwHOB640vt0A+jDGFNn/i4FZwEmtLLOKYy7jQnP0rZPordHrPowXwbS6EeAFYJUx5nGf4ecAdwMXGmPqAsybJiIZntfA2cDytii4ik+aumm9vTl63YfxIpga/WjgF8AZdhPJAhGZCDwDZACz7WHPA4hINxH5yJ43B/haRJYAC4D/GmM+afvNUPHC07zSqbmbFhMRRFyauokjh+zUzBjzNeDvE/GRn2EYY7YDE+3XG4FhrSmgUr60eWXbEHHjNroP44XeGauiiqZu2oZDDG63nv7xQo+0iipW6sap7ehbyeFw4zZ6+scLPdIqqrjc1u2cGudbx+HQGn080SOtoorLbd3l43ToR7c1HOLGaI0+buiRVlGl2Q70mqNvHafDaKCPI3qkVVRp9tboNdC3hsMBxjgPPaGKCRroVVRpdnly9BroW8PpMKCBPm5ooFdRxWW0Rt8WNHUTX/RIq6jS7PLk6PWj2xpWdzcJ9n0JKtbp2aKiiqdGr6mb1klwgpgEb3NVFds00Kuo4mlemaCpm1ZJsGv0ze7mQ02qYoAGehVVPIFe74xtHadDEBJpcjeFuyjqCNBAr6KKt3ml5uhbJcEJojX6uKFni4oqLvv5NnpnbOskOkUDfRzRs0VFFW8XCHoxtlUSHAJGA328OGR/9NHkynevpKG5IdzFaLVEZyJ/Oe0v5GXnhbsoEcdqJeLAoTX6VvHU6K/94FpSE1PDXRxly0zJ5N8X/rvNlxtTgX5t6Vrqm+rDXYxWcRkXq3evZlSPURro/WjWGn2b6NY+hwQpYWvl1nAXRfnITs0+LMuNqUC/8NcLw12EVqvcU0nm/2bqT+oA9uboNdC3RteMLiQ6a1n+G32EczzQ378RJsFhffdqoPdPuyluG0lOocnlxthfnCq26dkSYRKdiYAG+kDc2ryyTSQ6HRgDLrcG+nigZ0uE0Rr9wTXbNVC9Yap1Eq1bY2lyaaCPB4cM9CLSU0TmishKEVkhIrfaw7NEZLaIrLP/dwww/2R7mnUiMrmtNyBctlfU835BEcYYKuub+GT5zjZZrkMcCEKTS+9Y9MetqZs2kWj1akajSzs1iwfBXIxtBu4wxiwWkQxgkYjMBqYAc4wxfxWRe4B7gN/7zigiWcD9wAjA2PN+YIwpb8uNONJqG5qZ/OIC1hXXICJsK6vj0U/X8Olt4xhwVEarl5/g0PbNgXhSDQka6FslyWn9Irr+1XzSkw8MA8mJTs4enMPnq4qpb9TP4pHSPiWRxy8f3ubLPWSgN8bsAHbYr6tFZBXQHbgIOM2e7BVgHvsFemACMNsYUwZgf0GcA8xog7KHzdNfrGd9SQ29s1OZ+sEKju3eAYB5a4q9gb6kuoEXvt7E7ePzKK9t4sH/t5KHLzmWzNSkA5bndhvqm1xc/eICemelktk0mep6DWT+7O2PXvdPa3i+ML/fWMYx3dofMH5n5R7+u3QHHVMT6ZbZ7kgXL27taTo8v7BCal4pIrnAccAPQI79JQCwE8jxM0t3YJvP+0J7mL9lXwdcB9CrV69QinXYfL1uN9sr62lodvPlmmL+PflE6hqb+c8PWzj32KP46Yie/PKlhcxfWwLAvDUlXH9qPwD+/fVG/vnlRkb2zeLHLeX8d9kOJg7pynlDu+6zjnW7qrn42W+YfEoui7aUs2hLOalczNZdq4/49kYDT4DSQN86/btYFZLXrx3J6P6dDhhf09DMZyt2cuagHDq0SzzSxVNtLOhALyLpwEzgNmNMlfjcsGKMMSLSqqs6xphpwDSAESNGhP0K0dv527jrnaX7DJuzahf/mLeBqj3N/HJ0H4Z070C7RCf1TS46piaycHMZFXWNpCcn8O7iIgB+2FjGx8ut78OVOyoPCPT/+8kaahtdvPztZgDm3nkapz82T1tDBODSVjdtYkxeJ9Y/fC4JTv/7MT05gUuP73GES6UOl6DOFhFJxAryrxtj3rUH7xKRrvb4rkCxn1mLgJ4+73vYwyLe24sKOTonnX6d07zDfj9zKWt2VnPrmXmM6N2RlEQno/tbd7L9bvzRNLsNf/tsLb+enk9JdQMpiQ6e/3IDW0rrAFi5vWqfdeRvLuPzVbtwOoS6RhfdOqTQOSMZ2HsHqNrX3hy9trpprUBBXsWeYFrdCPACsMoY87jPqA8ATyuaycD7fmb/FDhbRDrarXLOtodFNJfbsLyokpP7ZvPqNSP599UjANhd08iEY47i9vFH4/lFc9kJPcnNTuWyE3oyun82r36/hUVbyrnljP5ccaKVguqUnsyEY3JYuaOKnZV7uOrfPzB06qfc/J8f6ZyRzORRuQAc072D99Z+rdH759YcvVIhC+ZsGQ38AjhDRArsv4nAX4HxIrIOOMt+j4iMEJF/A9gXYR8EFtp/f/FcmI1kG0pqqGt0MaxHJt0y23HW4Bz6dLJq9mPy9u2L4pxjj2LeXafTLsnJ78YP4KQ+Wcy88RTuOHsA5w/tSoJDeGrScE7MzWJXVQO/np7P4q3lHN+7Izur9vC78UczNs/KkR7TrT2e+OXSOxb90hy9UqELptXN10Cg38ln+pk+H7jW5/2LwIstLWA4LNlWAcCwnh28w47t3oFNu2s5pd+BF648TujdkbeuH+V9PyI3i7UPnYvDIaQkOgFYsb2SJy4fzkXDu7OtrI6eWanUNTZz5sAuTBzSVWv0h+A22rxSqVDFVKdmbWVpYSXpyQn07ZTuHTbllN4MyEknp31KSMvy3MF5fK+OfHX36SQnOuiSYS2jZ5bVPWxqUgIvTDkRwNv3iAZ6/7RGr1ToNND7sbSwgmO7t9/nNvsTemdxQu+sVi3XE9gPxsr9uzV1E4AnR58gzjCXRKnoodWi/TQ0u1i1o5phPTPDWAo3bq3R+6U1eqVCp2fLflbvqKbR5WZYj8zwFUIM2teUf5qjVyp0erbsZ2lhBQBDe3Q4+ISHkWC0Rh+AdoGgVOj0bNnPsqJKstOS6B7O/j3ErRdjA3Br6kapkOnZsp9Nu2vp3yUdCeMzSUUMGuf9c3lTN3oxVqlgaaDfz5bSOnpnH7p1zOEkaKAPRHP0SoVOzxYf9Y0uiqsb6BVEM8jDScSgXd3459kvmrpRKnh6tvjYVm51PtYrO+0QUx5emroJzFOj10CvVPD0bPHh6WUyImr0Guj98uTotfNKpYKngd7H1jIr0PcOd6AH9MZY/zytbvTh4EoFTwO9j62ltWQkJ5CZGt4n6lg1eg1k/ri9NXrdP0oFSwO9jy1ldfTKTg1r00qw0hJao/fPrakbpUKmgd7H1rLwN60Eq0avgd4/z41kWqNXKnga6G0ut6GwrD6oHiYPN4cDTd0E4LlIrTl6pYKngd62q2oPjS43vbPC27QSQASMBnq/jKZulAqZBnpbpDStBE+OXiOZPy77hilN3SgVPA30tm2eppURkKPXi7GBeWr0GueVCp4GetuWsloSHELXDqE9KvBwcDjA6KHxy3tnrEZ6pYKm0cS2eXcd3Tu2I8EZ/l2iqZvAvBdjNdArFbRDPjNWRF4EzgeKjTHH2sPeBAbYk2QCFcaY4X7m3QxUAy6g2Rgzok1K3cZcbsO3G3Zz2oAu4S4K4KmtCm7jxiHh/+KJJBrolQpdMA8Hfxl4BpjuGWCMudzzWkT+BlQeZP7TjTG7W1rAI2Hx1nLK65o4c1BkBHqHA8Q4cbldOCLgF0Yk8ebodbcoFbRDni7GmPlAmb9xYt1C+jNgRhuX64j6fNUuEhzCuKM7h7sogKdG76DZ3RzuokQcl+bolQpZa+tFY4Fdxph1AcYb4DMRWSQi1x1sQSJynYjki0h+SUlJK4sVmoKtFQzt0YH2KeHt48bDuhnIQZO7KdxFiThGUzdKhay1gX4SB6/NjzHGHA+cC9wkIuMCTWiMmWaMGWGMGdG585GtWRdV1EdE+3kPp4Dg1Bq9H54cvcZ5pYLX4kAvIgnApcCbgaYxxhTZ/4uBWcBJLV3f4eJyG3ZW7qFbOB8Gvh+nQ1M3gRjtvVKpkLWmRn8WsNoYU+hvpIikiUiG5zVwNrC8Fes7LIqr99DsNnTvGFmBXjTQ++Wp0Tu1DwSlgnbIQC8iM4DvgAEiUigi19ijrmC/tI2IdBORj+y3OcDXIrIEWAD81xjzSdsVvW0UldcD0D3iavROmlyao9/f3hx9eMuhVDQ5ZPNKY8ykAMOn+Bm2HZhov94IDGtl+Q67oopIDPQONHXj394cvUZ6pYIV962RvYFeUzdRwarRu8NdDKWiigb68no6piaSmhTMvWNHhlMcYDTQ+2P1daOBXqlQxH2g31pWF1EtbgASnKLNKwMwBhDt2lOpUMR1oK9vdLFgUxkn5maFuyj78OTo9YapA1k5eg30SoUirgP9txt209Dsjpg+bjwStB19QAbQy7BKhSZuA31FXSOv/7CVtCQnJ/WJrBp9gsOpF2MDsFI3mqNXKhRxG+jvemcpX6wu5pej+5Cc4Ax3cfaR4NQafSBGUzdKhSxuA/2qHVVcNLwbd04YcOiJj7AEh0MvxgbgNqKpG6VCFJeB3u027KqKrP5tfDkdTsChd8b6oa1ulApdXAb63bUNNLlMRDwf1p8EvTM2IOtirAZ6pUIRl4F+Z+UeALp2iMwafaLDgeCg0aWBfn9ao1cqdHEZ6LdXeAJ9ZNboE53WxeEmDfQHMEZr9EqFKi4D/c5Kq3+bSA30CfZzYhs0R38Aow3plQpZXAb6HZV7SEpwkJWWFO6i+JXg0Bp9IFqjVyp0cRvou3ZIidiubvemblxhLknkMYjm6JUKUVwG+p2Ve8hpH5lpG9gb6PVi7IGMtqNXKmRxGeh31zbQOSM53MUISGv0gRkDojV6pUISOZ2wH0HltY1kpUZmfh4g0c7RP58/jY82vBXm0kSWmsZT6JCggV6pUMRdoHe5DRX1TXSM0AuxAOnJqQB0ST2KZndNmEsTWTJTsshwtg93MZSKKnEX6CvqGjEGsiM40Ft3xsLbP5sZUc+yjQTXTc9na1lduIuhVFQ5ZI5eRF4UkWIRWe4zbKqIFIlIgf03McC854jIGhFZLyL3tGXBW6q8rhEgomv0TjvQu1yaotif2+iDwZUKVTAXY18GzvEz/AljzHD776P9R4qIE3gWOBcYDEwSkcGtKWxbKKu1bkKK5By9fb8ULqOBfn/GGO/+UUoF55CnjDFmPlDWgmWfBKw3xmw0xjQCbwAXtWA5baqstgGAjmmJYS5JYA67xupya6Dfn8sY7/5RSgWnNXWjm0VkqZ3a6ehnfHdgm8/7QntYWHlq9Nlpkdu80umwAplba/QH0NSNUqFraaB/DugHDAd2AH9rbUFE5DoRyReR/JKSktYuLiBPjj4zNXJr9Al2oG/WHP0BjDE4Nc4rFZIWBXpjzC5jjMsY4wb+hZWm2V8R0NPnfQ97WKBlTjPGjDDGjOjcuXNLihWU0ppG0pKcpCRG1uMDfXlSE1qjP5BbUzdKhaxFgV5Euvq8vQRY7meyhUCeiPQRkSTgCuCDlqyvLZXXNUZ0ixvYm7rRHP2BXG4N9EqF6pDt6EVkBnAa0ElECoH7gdNEZDjWA382A9fb03YD/m2MmWiMaRaRm4FPASfwojFmxeHYiFCU1TZGdBt6AIcn0GuN/gBWjj7cpVAquhwy0BtjJvkZ/EKAabcDE33efwQc0PQynEprG+iUHrkXYmFvjt6tNfoDGGO8/fUrpYITd2fM1tI6enSM7LtNnXaVtfkwBvrPVuzk0U9XY4yhtqGZbVFyt6nboKkbpUIUV10gVNQ1UrWnmdzstHAX5aAcR6BGP2PBVuauKSErLZmXv93EtrJ6Vj94DhV1TRzVxk/eKq7aQ5c26hba5TaaulEqRHFVo99catVae2WlhrkkB+c8TDl6t9t4vzy22DX4//loFdvKrEcrPvTflUx86itMgPUu2lLGxc9+Q11j8P3kbyip4aRH5vDyN5uCmr6stpFdVXswxrCzcg+TX1zAjAVbveONtrpRKmRxFei3lNYCkNspwmv0h+nO2HvfXcbklxbgchsKy+qZdFIvuvl0mvbRsp2U1TZSWttIZX0Ti7aU7zP/nFXFFGyrYO2u4HvU3GE/iH3Ggm1sr6g/6K+Uqj1NnP7YPEY+ModnvljPVS/8wJdrS3hu3gbvNG6z94tQKRWcOAv00VGjTzgMzSubXG7+u2wHCzaVsb2inkaXm2O7t+et60fx2E+HAVZtGqCwvJ6XvtnEz/75HdV79j6gfF2xFeA37Q4+0FfUW8tcs6uasf83lz++f2BLXJfbcPk/v+PqFxZQWd9Ez6x2TJu/kfXFNeS0T6awvI4quxxWO/qW7QOl4lVcBfrNpbUc1T4lom+WgsPTjn7h5jJqGpppaHYzb61153HvrDSO6pDC+UO77pP3LiyvY2NJLS63YfXOau/wdbus15tKavdZtttt+GFjqTflU1bbyN8/X0dZbaP3y8OzPf/5YStzVxcD1pfPL19awAtfb+SHTWUUbKvglH7ZXDumL9UNzTgE/njeYNwGFm0u9y5Du0BQKjRxFei3ltbRKzuya/NweO6M9QRXsFrcAPS290VKopOuPhdLi8rrvX2+r9xeBcCeJpc3r//V+t1M/WAFDc3Wow4/Xr6Ty6d9z+Kt5VTWNXH5P7/jic/XcsdbBeyubvAud8IxOSQ4hIWbrT7y8jeXM3dNCY9+ugaAG07tx8OXDOGswTkAnJibxVmDckh0Ct9tLAWgek8zSQlx9bFVqtXi6ozZUbknKh7ksbdG3/pl1Te6KK1pYObiIsbmdcLpEL5at5sEh9DVp3VNb5+WSIXl9RSWW0F91Y4q8jeXcfL/zMEYK63049YKXv52M99vtAL2fPsXwrLCSp74fC0bSmr42YgezF1TwgdLtuN0CMN6ZnLjaf3p0ynNmwKat8ZTszfktE/m9+cMoE+nNLpntuPWM/O45Yw82iU5GdO/E+/9WMSandUUVdQzsk9W63eMUnEkbgK9MYaSmga6RPBDwT08gb7Z3fJIv2l3LdvK6rhlxo+c8NDnlNU2cvv4o8lIsVrU9u+Svs+NR7md0khyOhiQk8GaXdXsrrFSLqt2VPGfH7ZSUWflyIf1zPTO88363Rhj+Hr9bgA+WbGTV7/fwqSTenHvuYMAq6VT305pvH/TaIb3zCQvJ511u6pxuw1frC6mvV2eEb2z9knJ3D7+aMbkdQLgypG9Ka5u4K53lgBwxsAuLd4vSsWjuGlHX1XfTGOzm85RFOhDTd0sK6wkLdlJcqKTS/7xDb2yUllaWAnApcd15/heHfnJ8T14v6CIv19x3D7z/ua0fpw9OIc3Fm7l0xW7AOjaIYXVO6up3tNMp/QkLjmuOwlOB4u2lNMu0cnX63az5aQ6iiqs5pnfbyxDBH57Zh4d05LITE2koq6J7PS9XU7kdcngo2U7ufDZr1lXXMOfzx/MrB+LOG9oVwI5fWAXcrOtbenbKY0eHSM//aZUJImbQF9SYzXzi4pAL6GnbowxXPDM1wAM7dGBiromKuqsIP/0pOO4YFg3AO6bOIg/njfogAuaPbNS6ZmVyjd27RzgqpN78+ina9i4u5bfjT+a356ZR21DM8f1zGTNzmr+Nnstv3urgESncNagHD5evpORfbLIsfP9udlpFNRV7NP3f15OOgDLi6p4+JJjmXRiL341ps/B94dDeOuGUbzy7WZO6O3v0QdKqYOJm9RNsX1RMBoCvf3I2JDujN24e29LmBXbq/jtGf2970fk7g2ODocctNXKFSft7Vl60km9vBdsPQE2LTmBs485ip+O6Elel3QWb61g6oXHMN6+gHre0G7e+fva9yvsX6MHSE5wcOXI3t67gA+lS0YKd00YyBkDc4KaXim1V/zU6O1AH005+lDujP12g9Uq5ffnDOSYbu0Z3b8Tr36/hdSkBLp2CP4CdP8uGbwweQSfr9pFx9RErh3bl8c+XcNwn9w8wFEdUvjo1rGsL65hUNf2VNY38avRfbh4+N5A77kxbZ8afZd0bjq9Hz89oSdKqSMj7gJ954y27cflcNh7MTb4QP/9hlK6dkjhhlP7emvsd5w9oEXdBZw5KIczB1k156tG9uLyET39NmlMdDoY1LU9AB3aJfLnC/Z99nsfPzV6h0O4a8LAkMuklGq5uAr0SQkObyuPSObJ0QebuimrbWTummIuGNptn7TMVSf3bnVZRISkhJbdoDSoq5Wm6RnhdyIrFesiP+q1keLqBjqnJ0fFXZWh3hn70jebqGt0ce3Yg1/UPNL6d8ng89+dSr/Okd23kFKxLm4uxpZUN9ClfeTn5wFvFw31TS7qG10H9CZ59ztL+GjZDsDarpe+2czEIUeRl5NxxMt6KP27pEfFl6tSsSyuAn2kP1nKIyXRSUqig901DQz68yfcM3OZd1xpTQNv5Rcyc1EhAI99uoY9TS7uPHtAuIqrlIpwcRPoy+sayUqN7GfF+spsl8RGu/OwN/O3UVxl3QfguQFqaVEl7ywq5M38bVwzpg99O6eHraxKqcgWF4HeGENFXROZaYnhLkrQMlMT2eTTNv5tuwa/pLACsH6h3DdrGSf3zeLOCVqbV0oFFheBvq7RRaPLTccoqtF3aJfo7VgMYJddo1+yrYIku4+ahmY3d00YSKI+LFspdRCHjBAi8qKIFIvIcp9hj4rIahFZKiKzRCQzwLybRWSZiBSISH4bljskFfVWh1yZ7aKnRt8xNQnfRjelNY00u9wUbKtg/DE5OAQG5GRwfK/MsJVRKRUdgmle+TLwDDDdZ9hs4F5jTLOI/C9wL/D7APOfbozZHWDcEVFuP/wiM4pq9Jmpe7+U+nZKo7S2gfnrSiiva+KCoV0Z3LU9Q3t00BYtSqlDOmSgN8bMF5Hc/YZ95vP2e+CyNi5Xm6q0a/QdU6OnRt/BN9B3TmNrWR1vLSwkOy2JMwbmcM6xmq5RSgWnLaLFr4CPA4wzwGciskhErjvYQkTkOhHJF5H8kpKSNijWXuV1UVijb2eVtUO7RLq0T6G4uoEvVhdzwbBu+oQlpVRIWhUxROQ+oBl4PcAkY4wxxwPnAjeJyLhAyzLGTDPGjDDGjOjcuXNrinWA8rroq9F7ypqdlkR2WhIVdU00utwMtvuWUUqpYLU40IvIFOB84Eqz/62bNmNMkf2/GJgFnNTS9bVGpV2j7xBFgd6To+9oB3qPaHjmrVIqsrQo0IvIOcDdwIXGmLoA06SJSIbnNXA2sNzftIdbeV0TqUlOkhOc4Vh9i3SwUzdZaUlk+dzRm5ut/cYopUITTPPKGcB3wAARKRSRa7Ba4WQAs+2mk8/b03YTkY/sWXOAr0VkCbAA+K8x5pPDshWHUFHXFFVt6GFvjT4rNYlOdo0+JdERFf3pK6UiSzCtbib5GfxCgGm3AxPt1xuBYa0qXRupqGukQxS1oQe8X0xZ6Ulk2f25985KC/qJTEop5REXzTcq6pvoGEXdHwB0TEskOy2JATkZZNk1+t6an1dKtUBc9EdfUdfIwKOiq7VKcoKTBfedhUOsfukTnaIdlymlWiQuAn1NQzPpydG3qZ4HkCQ4hem/GsnRORrolVKhi77o1wK1DS7SojDQ+xrVLzvcRVBKRamYz9EbY6htbCY9OXqaViqlVFuK7mpuEOqbXBgDqVFeo1fRo6mpicLCQvbs2RPuoqgYlJKSQo8ePUhMDL6BScxHv5qGZoCoT92o6FFYWEhGRga5ubnau6hqU8YYSktLKSwspE+fPkHPF/Opm7oGFwBpSZq6UUfGnj17yM7O1iCv2pyIkJ2dHfKvxZgP9FqjV+GgQV4dLi35bMV8oK/1BPokDfRKqfgU84G+rtFO3WirGxVHCgsLueiii8jLy6Nfv37ceuutNDY2HnSeiooK/vGPf3jfb9++ncsua5tnCk2dOpXHHnvM7/Du3bszfPhwBg8ezIwZM9pkfaGaN28e559/fljWfSTEfKDX1I2KN8YYLr30Ui6++GLWrVvH2rVrqamp4b777jvofPsH+m7duvHOO+8c7uJy++23U1BQwPvvv8/1119PU1PTYV+ny+U67OuIJDEf/eoaNdCr8Lntk9so2FnQpsscftRwnjznyYDjv/jiC1JSUvjlL38JgNPp5IknnqBPnz488MADvPXWW8yaNYvKykqKioq46qqruP/++7nnnnvYsGEDw4cPZ/z48dx0002cf/75LF++nJdffpn33nuP2tpa1q1bx5133kljYyOvvvoqycnJfPTRR2RlZfGvf/2LadOm0djYSP/+/Xn11VdJTQ2uj6a8vDxSU1MpLy+nS5cuPProo7z11ls0NDRwySWX8MADD/Doo4+SnJzMb3/7W26//XaWLFnCF198wRdffMELL7zA66+/zo033sjChQupr6/nsssu44EHHgAgNzeXyy+/nNmzZ3P33XeTmZnJbbfdRmpqKmPGjGn1cYlkcVCjt7650zVHr+LEihUrOOGEE/YZ1r59e3r16sX69esBWLBgATNnzmTp0qW8/fbb5Ofn89e//pV+/fpRUFDAo48+esByly9fzrvvvsvChQu57777SE1N5ccff2TUqFFMnz4dgEsvvZSFCxeyZMkSBg0axAsv+O3o1q/FixeTl5dHly5d+Oyzz1i3bh0LFiygoKCARYsWMX/+fMaOHctXX30FQH5+PjU1NTQ1NfHVV18xbpz1ALuHH36Y/Px8li5dypdffsnSpUu968jOzmbx4sVcfPHF/PrXv+bDDz9k0aJF7Ny5M7SdHGViPvp5Lsamao5ehcHBat7hNH78eLKzrW41Lr30Ur7++msuvvjig85z+umnk5GRQUZGBh06dOCCCy4AYMiQId5gunz5cv74xz9SUVFBTU0NEyZMOGRZnnjiCV566SXWrl3Lhx9+CMBnn33GZ599xnHHHQdATU0N69at4+qrr2bRokVUVVWRnJzM8ccfT35+Pl999RVPPfUUAG+99RbTpk2jubmZHTt2sHLlSoYOHQrA5ZdfDsDq1avp06cPeXl5AFx11VVMmzYtlF0YVWK+Rl/b2ExSgoNEZ8xvqlIADB48mEWLFu0zrKqqiq1bt9K/f3/gwCZ6wTTZS07e+9Abh8Phfe9wOGhutipUU6ZM4ZlnnmHZsmXcf//9QbX3vv3221mxYgUzZ87kmmuuYc+ePRhjuPfeeykoKKCgoID169dzzTXXkJiYSJ8+fXj55Zc55ZRTGDt2LHPnzmX9+vUMGjSITZs28dhjjzFnzhyWLl3Keeedt08Z0tLi8wltMR/9ahua9WYpFVfOPPNM6urqvOkUl8vFHXfcwZQpU7z58tmzZ1NWVkZ9fT3vvfceo0ePJiMjg+rq6latu7q6mq5du9LU1MTrr78e0rwXXnghI0aM4JVXXmHChAm8+OKL1NTUAFBUVERxcTEAY8eO5bHHHmPcuHGMHTuW559/nuOOOw4RoaqqirS0NDp06MCuXbv4+OOP/a5r4MCBbN68mQ0bNgCErbXPkRLzgb4uBnquVCoUIsKsWbN4++23ycvL4+ijjyYlJYVHHnnEO81JJ53ET37yE4YOHcpPfvITRowYQXZ2NqNHj+bYY4/lrrvuatG6H3zwQUaOHMno0aMZOHBgyPP/+c9/5vHHH+ess87i5z//OaNGjWLIkCFcdtll3i+hsWPHsmPHDkaNGkVOTg4pKSmMHTsWgGHDhnHccccxcOBAfv7znzN69Gi/60lJSWHatGmcd955HH/88XTp0qVF2xstxBgT7jIcYMSIESY/P79NlnXd9Hy2lNbx6e3j2mR5Sh3KqlWrGDRoULiLEdDLL79Mfn4+zzzzTLiLolrI32dMRBYZY0b4mz7ma/S1jc16s5RSKq7FfE6jtsFFRkrMb6ZSQZsyZQpTpkwJdzHUERRUjV5EXhSRYhFZ7jMsS0Rmi8g6+3/HAPNOtqdZJyKT26rgwbIuxmqgV0rFr2BTNy8D5+w37B5gjjEmD5hjv9+HiGQB9wMjgZOA+wN9IRwuVXuaSNcavVIqjgUV6I0x84Gy/QZfBLxiv34FuNjPrBOA2caYMmNMOTCbA78wDhu321Ba00jnjORDT6yUUjGqNRdjc4wxO+zXO4EcP9N0B7b5vC+0hx1ARK4TkXwRyS8pKWlFsfYqr2uk2W3oooFeKRXH2qTVjbHaaLaqnaYxZpoxZoQxZkTnzp3bolgUVzcA0CUjpU2Wp1S0EBGuuuoq7/vm5mY6d+58RLrifeyxxxg4cCDDhw/nxBNP9N64Fchpp52Gpzl1bm4uu3fvDnmd8+bN49tvvw15vkDry83NZciQIQwdOpRTTz2VLVu2hLzstjBlypQ26UG0NYF+l4h0BbD/F/uZpgjo6fO+hz3siCixA72mblS8SUtLY/ny5dTX1wPWnbDdu/v9Md2mnn/+eWbPnu3tjGzOnDkciXt1WhroD2bu3LksXbqU0047jYceeqhNl+2PpxuJw6E1Vyk/ACYDf7X/v+9nmk+BR3wuwJ4N3NuKdYZkb41eA70Kjwc+XMHK7VVtuszB3dpz/wXHHHK6iRMn8t///pfLLruMGTNmMGnSJG/Pj7W1tdxyyy0sX76cpqYmpk6dykUXXcTmzZv5xS9+QW1tLQDPPPMMp5xyCvPmzWPq1Kl06tSJ5cuXc8IJJ/Daa68d0EfOI488wrx582jfvj1g9Zo5ebLV2G7OnDnceeedNDc3c+KJJ/Lcc8/t03/O/l577TWeeuopGhsbGTlyJP/4xz9wOp188skn/OEPf8DlctGpUydeeOEFnn/+eZxOJ6+99hpPP/00AwcO5IYbbmDr1q0APPnkk4wePZrS0lImTZpEUVERo0aNCupLaNSoUd4O00pKSvwud8iQIXz11Vd06NCBTp068cQTT3D11Vdz9dVX84tf/IK8vLyA+/VPf/oTHTt2ZPXq1axZs4ZbbrmF2bNn07NnT5KSkg5ZvmAE27xyBvAdMEBECkXkGqwAP15E1gFn2e8RkREi8m8AY0wZ8CCw0P77iz3siCiutjoz0hq9ikdXXHEFb7zxBnv27GHp0qWMHDnSO+7hhx/mjDPOYMGCBcydO5e77rqL2tpaunTpwuzZs1m8eDFvvvkmv/3tb73z/Pjjjzz55JOsXLmSjRs38s033+yzvqqqKqqrq+nbt+8BZdmzZw9TpkzhzTffZNmyZTQ3N/Pcc88FLPuqVat48803+eabbygoKMDpdPL6669TUlLCr3/9a2bOnMmSJUt4++23yc3N5YYbbvA+wGTs2LHceuut3H777SxcuJCZM2dy7bXXAvDAAw8wZswYVqxYwSWXXOIN2AfzySefeHv2DLTc0aNH880337BixQr69u3r/UL97rvvOOWUUw66XxcvXszf//531q5dy6xZs1izZg0rV65k+vTpbfYrJagavTFmUoBRZ/qZNh+41uf9i8CLLSpdK5VUN5CW5NS+blTYBFPzPlyGDh3K5s2bmTFjBhMnTtxn3GeffcYHH3zgfbzfnj172Lp1K926dePmm2/2Bte1a9d65znppJPo0aMHAMOHD2fz5s1BP7BjzZo19OnTh6OPPhqAyZMn8+yzz3Lbbbf5nX7OnDksWrSIE088EYD6+nq6dOnC999/z7hx4+jTpw8AWVlZfuf//PPPWblypfd9VVUVNTU1zJ8/n3fffReA8847j44dA7f2Pv300ykrKyM9PZ0HH3zwoMsdO3Ys8+fPp3fv3tx4441MmzaNoqIiOnbsSFpaGpWVlQfdr57tmT9/PpMmTcLpdNKtWzfOOOOMg+7XYMV0BCyubqBLe70Qq+LXhRdeyJ133sm8efMoLS31DjfGMHPmTAYMGLDP9FOnTiUnJ4clS5bgdrtJSdl7/vimWZxO5wE55fbt25Oens7GjRv91upDYYxh8uTJ/M///M8+wz391R+K2+3m+++/36f8oZo7dy6ZmZlceeWV3H///Tz++OMBlztu3DieffZZtm7dysMPP8ysWbN45513vJ2tPfHEEwH365HoOjmm+7opqW7QtI2Ka7/61a+4//77GTJkyD7DJ0yYwNNPP+3NUf/4448AVFZW0rVrVxwOB6+++mrIz1a99957uemmm6iqsq5L1NTUMH36dAYMGMDmzZu9T7h69dVXOfXUUwMu58wzz+Sdd97xdk1cVlbGli1bOPnkk5k/fz6bNm3yDgcO6GL57LPP5umnn/a+LygoAKyA/J///AeAjz/+mPLy8oNuT0JCAk8++STTp0+nrKws4HJ79uzJ7t27WbduHX379mXMmDHerpQh+P06btw43nzzTVwuFzt27GDu3LkHLV+wYirQX/D014x//EvvX8G2Cg30Kq716NFjn3ywx5/+9CeampoYOnQoxxxzDH/6058A+M1vfsMrr7zCsGHDWL16dci1zRtvvJHTTz+dE088kWOPPZaxY8ficDhISUnhpZde4qc//SlDhgzB4XBwww03BFzO4MGDeeihhzj77LMZOnQo48ePZ8eOHXTu3Jlp06Zx6aWXMmzYMO8Toy644AJmzZrF8OHDvU+bys/PZ+jQoQwePJjnn38egPvvv5/58+dzzDHH8O6779KrV69DblPXrl2ZNGkSzz77bMDlAowcOdKbmho7dixFRUXe1Faw+/WSSy4hLy+PwYMHc/XVVzNq1KjgdvwhxFQ3xbe98SONLvc+w64a2ZtT+ndqq6IpdUiR3k2xin6hdlMcUzn6J684LtxFUEqpiBNTqRullFIH0kCv1GEQiSlRFRta8tnSQK9UG0tJSaG0tFSDvWpzxhhKS0tDbjYaUzl6pSJBjx49KCwspK16YVXKV0pKivfGtWBpoFeqjSUmJnrvdFQqEmjqRimlYpwGeqWUinEa6JVSKsZF5J2xIlICtPSRLp2A0B9RE5l0WyJPrGwH6LZEqpZuS29jjN/H80VkoG8NEckPdBtwtNFtiTyxsh2g2xKpDse2aOpGKaVinAZ6pZSKcbEY6KeFuwBtSLcl8sTKdoBuS6Rq822JuRy9UkqpfcVijV4ppZQPDfRKKRXjYibQi8g5IrJGRNaLyD3hLk+oRGSziCwTkQIRybeHZYnIbBFZZ/8P/Mj6MBKRF0WkWESW+wzzW3axPGUfp6Uicnz4Sn6gANsyVUSK7GNTICITfcbda2/LGhGZEJ5S+yciPUVkroisFJEVInKrPTzqjs1BtiXqjo2IpIjIAhFZYm/LA/bwPiLyg13mN0UkyR6ebL9fb4/PDXmlxpio/wOcwAagL5AELAEGh7tcIW7DZqDTfsP+D7jHfn0P8L/hLmeAso8DjgeWH6rswETgY0CAk4Efwl3+ILZlKnCnn2kH25+1ZKCP/Rl0hnsbfMrXFTjefp0BrLXLHHXH5iDbEnXHxt6/6fbrROAHe3+/BVxhD38euNF+/Rvgefv1FcCboa4zVmr0JwHrjTEbjTGNwBvARWEuU1u4CHjFfv0KcHH4ihKYMWY+ULbf4EBlvwiYbizfA5ki0vWIFDQIAbYlkIuAN4wxDcaYTcB6rM9iRDDG7DDGLLZfVwOrgO5E4bE5yLYEErHHxt6/NfbbRPvPAGcA79jD9z8unuP1DnCmiEgo64yVQN8d2ObzvpCDfwgikQE+E5FFInKdPSzHGLPDfr0TyAlP0VokUNmj9VjdbKczXvRJoUXNttg/94/Dqj1G9bHZb1sgCo+NiDhFpAAoBmZj/eKoMMY025P4lte7Lfb4SiA7lPXFSqCPBWOMMccD5wI3icg435HG+t0WlW1ho7nstueAfsBwYAfwt7CWJkQikg7MBG4zxlT5jou2Y+NnW6Ly2BhjXMaY4UAPrF8aAw/n+mIl0BcBPX3e97CHRQ1jTJH9vxiYhXXwd3l+Otv/i8NXwpAFKnvUHStjzC77xHQD/2JvCiDit0VEErEC4+vGmHftwVF5bPxtSzQfGwBjTAUwFxiFlSrzPAzKt7zebbHHdwBKQ1lPrAT6hUCefdU6CeuCxQdhLlPQRCRNRDI8r4GzgeVY2zDZnmwy8H54Stgigcr+AXC13cLjZKDSJ40QkfbLU1+CdWzA2pYr7FYRfYA8YMGRLl8gdh73BWCVMeZxn1FRd2wCbUs0HhsR6SwimfbrdsB4rGsOc4HL7Mn2Py6e43UZ8IX9Syx44b4C3YZXsidiXYnfANwX7vKEWPa+WC0ElgArPOXHysPNAdYBnwNZ4S5rgPLPwPrZ3ISVW7wmUNmxWhw8ax+nZcCIcJc/iG151S7rUvuk6+oz/X32tqwBzg13+ffbljFYaZmlQIH9NzEaj81BtiXqjg0wFPjRLvNy4M/28L5YX0brgbeBZHt4iv1+vT2+b6jr1C4QlFIqxsVK6kYppVQAGuiVUirGaaBXSqkYp4FeKaVinAZ6pZSKcRrolVIqxmmgV0qpGPf/AY7gG1yHdpSqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparison between optimal and expected reward\n",
    "plt.figure(0)\n",
    "plt.title(\"Reward - Optimal vs Collected\")\n",
    "plt.plot(opt_reward_evolution, color = 'green')\n",
    "plt.plot(np.mean(changes_collected_rewards, axis=0))\n",
    "plt.legend([\"Optimal Reward\", \"Mean Collected Reward\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
